---
layout: post
title: "기계학습, T-SNE"
description: "T-SNE, T-분산 확률근접배치"
categories: [MachineLearning]
tags: [Machine Learning, Unsupervised Learning, T-SNE, T - Distributed Stochastic Neighbor Embedding]
use_math: true
redirect_from:
  - /2021/07/26/
---

* Kramdown table of contents
{:toc .toc}      

[sample](https://ratsgo.github.io/machine%20learning/2017/04/28/tSNE/){:target="_ blank"}             
[2](https://m.blog.naver.com/xorrms78/222112752837){:target="_ blank"}             
[3](https://bcho.tistory.com/1210){:target="_ blank"}             
[wiki](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding){:target="_ blank"}             
[5](https://lovit.github.io/nlp/representation/2018/09/28/tsne/){:target="_ blank"}             
[6](https://skyeong.net/284){:target="_ blank"}             


# T - Distributed Stochastic Neighbor Embedding

> 각 데이터 지점에 2차원 또는 3차원 맵의 위치를 제공하여 고차원 데이터를 시각화하기 위한 통계적 방법         

> 차원축소 기법은 크게 두 종류로 나뉘어 진다.        
> 첫 번째는 중요한 feature 를 전체중에 선택하는 feature selection 방법이고,           
> 두 번째는 전체 feature를 적은 수의 feature로 융합하는 feature extract 방법이다           
> T-SNE는 feature extract 방법            

t-SNE 알고리즘은 두 가지 주요 단계로 구성됩니다.          
첫째, t-SNE는 유사한 물체는 더 높은 확률을 할당하고 다른 점은 더 낮은 확률을 할당하는 방식으로 고차원 객체 쌍에 대한 확률 분포를 구성합니다.           
둘째, t-SNE는 저차원 지도의 점에 대해 유사한 확률 분포를 정의하며, 지도에서 점의 위치에 대해 두 분포 사이의 쿨백-라이블러 발산(KL 발산)을 최소화한다.         
원래의 알고리즘이 객체 사이의 유클리드 거리를 유사성 측정 기준의 기초로 사용하지만, 적절하게 변경할 수 있습니다.             

t-SNE 그림은 종종 클러스터를 표시하는 것처럼 보이지만 
시각적 클러스터는 선택한 모수화의 영향을 강하게 받을 수 있으므로 t-SNE에 대한 모수를 잘 이해해야 합니다. 
이러한 "클러스터"는 클러스터되지 않은 데이터에도 나타날 수 있으므로 잘못된 소견일 수 있습니다. 
따라서 매개변수를 선택하고 결과를 검증하려면 대화형 탐사가 필요할 수 있습니다.
t-SNE는 종종 잘 분리된 단서를 복구할 수 있는 것으로 입증되었다.


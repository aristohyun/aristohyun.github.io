---
layout: post
title: "기계학습, T-SNE"
description: "T-SNE, T-분산 확률근접배치"
categories: [MachineLearning]
tags: [Machine Learning, Unsupervised Learning, T-SNE, T - Distributed Stochastic Neighbor Embedding]
use_math: true
redirect_from:
  - /2021/07/26/
---

* Kramdown table of contents
{:toc .toc}      

[2](https://m.blog.naver.com/xorrms78/222112752837){:target="_ blank"} 
[3](https://bcho.tistory.com/1210){:target="_ blank"} 
[sample](https://ratsgo.github.io/machine%20learning/2017/04/28/tSNE/){:target="_ blank"}             
       
            
[wiki](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding){:target="_ blank"}             
[5](https://lovit.github.io/nlp/representation/2018/09/28/tsne/){:target="_ blank"}             
[6](https://skyeong.net/284){:target="_ blank"}             

# 고차원의 시각화

> 많은 기법이 제시되었지만 이는       
> 사람의 해석을 필요로 하며, 2차원 이상의 차원으로 매핑하는 단점이 있었다           
> PCA등의 차원감소 방법은 효과적인 성능을 보이지만 시각화에 한계가 있음              


# SNE (Stochastic Neighbor Embedding)

> 고차원의 원 공간에 존재하는 데이터 $x$의 이웃간의 거리를 최대한 보존하는 저차원의 $y$를 학습하는 방법           
> Stochastic : 거리 정보를 확률적으로 나타내기 때문

@
p_ {j|i} = \frac {exp(-|x_ i - x_ j|^2 / 2\sigma_ i ^2)}{\sum \limits_ {k \neq i}^{} exp(-|x_ i - x_ k|^2 / 2\sigma_ i ^2)}
@

@
q_ {j|i} = \frac {exp(-|y_ i - y_ j|^2)}{\sum \limits_ {k \neq i}^{} exp(-|y_ i - y_ k|^2)}
@

p는 고차원 원공간에 존재하는 $i$번째 개체 $x_ i$가 주어졌을 때, $j$번째 이웃인 $x_ j$가 선택될 확률            
q는 저차원에 임베딩된 $i$번째 개체 $y_ i$가 주어졌을 때, $j$번째 이웃인 $y_ j$가 선택될 확률             

> SNE의 목적은 p와 q의 분포 차이가 최대한 작게끔 하고자 함
> 차원 축소가 제대로 이루어 졌다면, 고차원에서 이웃으로 뽑힐 확률과, 저차원에서 선택될 확률이 비슷하기 때문


## 비용 함수

> `Kullback-Leibler divergence`            
> 두 확률분포가 얼마나 비슷한지 측정하는 지표          
> 완전히 다르면 1, 동일하면 0의 값을 가짐        

@
\begin{align\*}
Cost &= \sum {KL(P_ i || Q_ i)} \\\ 
&= \sum \limits_ {i}^{} \sum \limits_ {j}^{} {p_ {j|i} log \frac {p_ {j|i}}{q_ {j|i}} } 
\end{align\*}
@

SNE 연구진은 계산 속도를 높이기 위해 몇 가지 학습 트릭을 도입.         
$\sigma_ i$는 각 개체마다 데이터 밀도가 달라서 이웃으로 뽑힐 확률이 왜곡되는 현상을 방지하기 위한 값인데,         
반복 실험 결과 p를 계산할 때 쓰는 $\sigma_ i$는 고정된 값을 써도 성능에 큰 차이를 보이지 않았다고 함.     
따라서 $\sigma_ i$ 계산을 생략하게 됨       

<br/>

i에서 j가 이웃을 뽑힐 확률과 j에서 i가 뽑힐 확률이 동일하다고 생각해도 됨         
따라서          

@
p_ {ij} = \frac {p_ {j|i} + p_ {i|j}}{2} , q_ {ij} = \frac {q_ {j|i} + q_ {i|j}}{2}
@

@
\begin{align\*}
Cost &= \sum {KL(P_ i || Q_ i)} \\\ 
&= \sum \limits_ {i}^{} \sum \limits_ {j}^{} {p_ {j|i} log \frac {p_ {j|i}}{q_ {j|i}} } \\\ 
\frac {d C}{d y_ i} &= 4 \sum \limits_ {j}^{} {(y_ j - y_ i)(p_ {ij} - q_ {ij})} 
\end{align\*}
@


최종적으로 구하고자 하는 미지수는 저차원에 임베딩된 좌표값 $y_ i$          
SNE는 그래디언트 디센트(gradient descent)[^1] 방식으로 $y_ i$ 들을 업데이트한다. 
즉, 처음에 $y_ i$ 를 랜덤으로 초기화해놓고 위에서 구한 그래디언트의 반대방향으로 조금씩 $y_ i$ 들을 갱신해 나가는 것
$y_ i$ 의 그래디언트를 보면 우리가 이미 모두 알고 있는 값들이므로 업데이트를 여러번 반복 수행하기만 하면 됨


# T-SNE (T - Distributed[^1] Stochastic Neighbor Embedding)

> SNE가 전제하는 확률분포는 가우시안 분포        
> 그러나 가우시안 분포는 꼬리가 두텁지 않아서
> 적당히 떨어져있는 데이터와, 아주 멀리 떨어져있는 데이터가 선택될 확률이 크게나지 않음
> => Crowding Problem
> 가우시안 분포보다 꼬리가 두터운 t-분포를 쓴 것이 t-SNE
> q_ {ij}에만 t분포를 적용하고, p_ {ij}는 SNE와 같음

@
q_ {ij} = \frac {(1 + |y_ i - y_ j|^2)^{-1}}{\sum \limits_ {k \neq l}^{}(1 + |y_ k - y_ l|^2)^{-1}}
@

해야할거
1. t분포 설명 각주에다가 적기
2. 어떻게 만드는지 수식
3. 이점은 무엇인가
4. 스니도 적기


> 각 데이터 지점에 2차원 또는 3차원 맵의 위치를 제공하여 고차원 데이터를 시각화하기 위한 통계적 방법         

> 차원축소 기법은 크게 두 종류로 나뉘어 진다.        
> 첫 번째는 중요한 feature 를 전체중에 선택하는 feature selection 방법이고,           
> 두 번째는 전체 feature를 적은 수의 feature로 융합하는 feature extract 방법이다           
> T-SNE는 feature extract 방법            

t-SNE 알고리즘은 두 가지 주요 단계로 구성됩니다.          
첫째, t-SNE는 유사한 물체는 더 높은 확률을 할당하고 다른 점은 더 낮은 확률을 할당하는 방식으로 고차원 객체 쌍에 대한 확률 분포를 구성합니다.           
둘째, t-SNE는 저차원 지도의 점에 대해 유사한 확률 분포를 정의하며, 지도에서 점의 위치에 대해 두 분포 사이의 쿨백-라이블러 발산(KL 발산)을 최소화한다.         
원래의 알고리즘이 객체 사이의 유클리드 거리를 유사성 측정 기준의 기초로 사용하지만, 적절하게 변경할 수 있습니다.             

t-SNE 그림은 종종 클러스터를 표시하는 것처럼 보이지만 
시각적 클러스터는 선택한 모수화의 영향을 강하게 받을 수 있으므로 t-SNE에 대한 모수를 잘 이해해야 합니다. 
이러한 "클러스터"는 클러스터되지 않은 데이터에도 나타날 수 있으므로 잘못된 소견일 수 있습니다. 
따라서 매개변수를 선택하고 결과를 검증하려면 대화형 탐사가 필요할 수 있습니다.
t-SNE는 종종 잘 분리된 단서를 복구할 수 있는 것으로 입증되었다.


[^1]: 경사 하강법(傾斜下降法, Gradient descent)은 1차 근삿값 발견용 최적화 알고리즘이다. 기본 개념은 함수의 기울기(경사)를 구하고 경사의 절댓값이 낮은 쪽으로 계속 이동시켜 극값에 이를 때까지 반복시키는 것이다.
[^2]: T-분포란, 

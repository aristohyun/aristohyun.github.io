---
layout: post
title: "기계학습, ROC Curve"
description: "ROC Curve"
categories: [MachineLearning]
tags: [Machine Learning, Supervised Learning, ROC Curve, kaggle]
use_math: true
redirect_from:
  - /kaggle/10
  - /blog/kaggle/10
---

* Kramdown table of contents
{:toc .toc}


# 민감도, 특이도    

|실제\\추측 | True | False |
|:---:|:---:|:---:|
|Positive|True Positive| <red>False Negative</red><br/><blue>Type II Error</blue>|   
|Negative|<red> False Positive</red><br /><blue> Type I Error </blue>|True Negative|    


<br />

- 민감도 Sensitivity     
Recall, TPR, True Positive Rate = $\;\; \frac{TP}{TP + FN} $    
실제 병에 걸린 사람이 양성(Positive) 판정을 받는 비율 (피관찰자 기준)    
<br />    
        
- 특이도 Specificity    
TNR, True Negative Rate = $\;\; \frac{TN}{FP + TN} $    
정상인이 음성(Negative) 판정을 받는 비율    
<br />    
        
- FPR, False Positive Rate, Type I Error Rate    
1 - Specifity = $\;\; \frac{FP}{FP + TN} $    
<br />    
     
- 정확도 Accuracy = $\;\; \frac{TP + TN}{TP + FP + FN + TN} $    
전체 데이터중 제대로 분류된 데이터 비율    
<br />    
    
- 에러율 Error Rate = $\;\; \frac{FP + FN}{TP + FP + FN + TN} $    
전체 데이터중 제대로 분류되지 않은 데이터 비율  
<br />    

- 정밀도 Precision = $\;\; \frac{TP}{TP + FP} $    
Positive로 예측했을 때 실제로 Positive인 비율 (관찰자 기준)     
<br />    


# ROC Curve    
> 수신자 조작 특성 (Receiver Operating Characteristic)[^1]      
> 다양한 threshold(임계값)에 대한 이진분류기의 성능을 한번에 표시한 것    
> 좌상단에 붙어있을 수록(곡선 아래 면적이 넓을 수록) 좋은 분류기    

![image](https://user-images.githubusercontent.com/32366711/124377376-9d9f8c80-dce6-11eb-98ef-57e6af7a0ae4.png){: width="500" height="500"}    


## 1. TPR, FPR이란    
> TPR : 있을 때 있다고 한것. 병이 있는데, 병이 있다고 하는 것    
> FPR : 없을 때 있다고 한 것. 병이 없는데, 있다고 하는 것[^1]    

![image](https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2020-08-05-ROC/pic3.png){: width="450" height="450"}    

## 2. 점의 위치의 의미    
> 곡선위의 점은 임계값의 위치에따른 TPR, FPR을 의미함[^1]    

![image](https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2020-08-05-ROC/pic6.gif) 

## 3. 곡선의 휨 정도의 의미    
> 곡선이 위에 붙을 수록, TPR, FPR을 더 잘 구분할 수 있다는 의미[^1]     
   
![image](https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2020-08-05-ROC/pic7.gif)    

## 4. 면적에 대한 의미    
> 면적은 분류기의 성능    

|  AUC <br/>(Area Under Curve) | Evaluation |
|:--------------------:|:----------:|
|       0.9 ~          |  Excellent |
|     0.8 ~ 0.9     |    Good    |
|     0.7 ~ 0.8     |    Fair    |
|     0.6 ~ 0.7     |    Poor    |
|        ~ 0.6      |    Fail    |


## practice    

~~~ python
# 예측에 대한 정확도를 분석하는 것이기에
# 훈련셋을 테스트셋으로 나누어서 확인
x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size = 0.3, random_state=21)

y_pred_prob_knn = knn.predict_proba(x_test)[:,1]
y_pred_prob_logistic = logreg.predict_proba(x_test)[:,1]

fpr_knn, tpr_knn, thresholds_knn = roc_curve(y_test, y_pred_prob_knn)
fpr_logistic, tpr_logistic, thresholds_logistic = roc_curve(y_test, y_pred_prob_logistic)

print("knn - auc : ",roc_auc_score(y_test, y_pred_prob_logistic))
print("logistic - auc : ",roc_auc_score(y_test, y_pred_prob_logistic))

# Plot ROC curve
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr_knn, tpr_knn, label='KNN')
plt.plot(fpr_logistic, tpr_logistic, label='Logistic')
plt.legend()

plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC')
plt.show()
~~~
![image](https://user-images.githubusercontent.com/32366711/124723719-4861b600-df46-11eb-9404-ba38fe7d9471.png)



# 참고 사이트
- [로스카츠의 AI 머신러닝](https://losskatsu.github.io/machine-learning/stat-roc-curve/#2-%EB%AF%BC%EA%B0%90%EB%8F%84%EC%99%80-%ED%8A%B9%EC%9D%B4%EB%8F%84){: target="_ blank"}    
- [공돌이의 수학정리 노트](https://angeloyeo.github.io/2020/08/05/ROC.html){: target="_ blank"}




[^1]: 공돌이의 수학정리 노트, https://angeloyeo.github.io/2020/08/05/ROC.html

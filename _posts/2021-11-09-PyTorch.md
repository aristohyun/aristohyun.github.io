---
layout: post
title: "AI, PyTorch"
description: "AI, 이건명 교수님"
categories: [AI]
tags: [2021-2, AI, Artificial Intelligence, PyTorch, 이건명]
use_math: true
redirect_from:
  - /2021/11/09/
---

* Kramdown table of contents
{:toc .toc}  

# PyTorch

~~~python
# NumPy 배열로 된 데이터 차원을 PyTorch에서 다룰 수 있는 '텐서'로 변환
torch.Tensor() 
torch.LongTensor() # Long 텐서
TensorDataSet() # 쌍으로 대응
TensorLoader(tensorDataset, batch_size=64, shuffle=True) # TensorDataSet 객체를 학습/추론에 사용하기 편한 객체로 변환
~~~

~~~python
import numpy as np
Import torch 

A = torch.tensor([[1., -1.], [1., -1.]])
print('A = ', A)
B = torch.tensor(np.array([[1, 2, 3], [4, 5, 6]]))
print('B = ', B)

C = torch.rand(3,3)
print('C = ', C)

D = C.numpy()
print('D = ', D)

E = B.view(1,1,2,3)
print('E = ', E)

print('sum of A = ', A.sum())
print('mean of A = ', A.mean()
~~~

## 계산 그래프

![image](https://user-images.githubusercontent.com/32366711/140863922-3da7c35a-7a2f-404f-ac99-895c01094061.png)

![image](https://user-images.githubusercontent.com/32366711/140863945-25b393d7-2e5c-45da-8118-cffcc92d2036.png)

~~~python
import torch
from torch.autograd import Variable
x = Variable(torch.tensor([[2.]]), requires_grad = True)
print('x = ', x)
print('x.data = ', x.data)
print('x.grad = ', x.grad)
print('x.grad_fn() = ', x.grad_fn)

y = x * x * 3
print('\ny = ', y)
print('y.data = ', y.data)
print('y.grad = ', y.grad)
print('y.grad_fn() = ', y.grad_fn)

z = y**2 
print('\nz = ', z)
print('z.data = ', z.data)
print('z.grad = ', z.grad)

z.backward( )
print('\nAfter invocation of backward()')
print('\nx = ', x)
print('x.data = ', x.data)
print('x.grad = ', x.grad)
print('x.grad_fn( ) = ', x.grad_fn)
print('\ny = ', y)
print('y.data = ', y.data)
print('y.grad = ', y.grad)
print('y.grad_fn( ) = ', y.grad_fn)
print('\nz = ', z)
print('z.data = ', z.data)
print('z.grad = ', z.grad)
~~~

## 기초 학습/추론

~~~python
# 신경망 모델을 학습 모드로 전환
model.train( ) 

# 신경망 모델을 추론 모델로 전환
model.eval( ) 

# 역전파 오차(그레디언트) 계산의 초기화
optimizer.zero_grad( ) 

# 추론 과정에서는 그레디언트 계산 불필요
with.torch.no_grad( ) 

~~~



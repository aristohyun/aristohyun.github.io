---
layout: post
title: "AI, 4장 기계학습"
description: "AI, 이건명 교수님"
categories: [AI]
tags: [2021-2, AI, Artificial Intelligence, 이건명]
use_math: true
redirect_from:
  - /2021/10/05/
---

* Kramdown table of contents
{:toc .toc}  


# 기계학습

> Machine Learning           
> 경험을 통해 작업을 더 효율적으로 처리할 수 있도록          
> 시스템의 구조나 파라미터를 바꾸는 것

컴퓨터가 데이터로부터 특정 문제해결을 위한 지식을 자동으로 추출해서 사용할 수 있게 하는 기술

직접 알고리즘을 짠다면 복잡하거나 성능이 제대로 안나올 수 있지만,             
기계학습을 이용한다면 데이터를 학습시킴에 따라 자동으로 분류 규칙이나 프로그램을 생성함          

## 학습 방법

> 귀납적 학습          
> 사례들을 일반화하여 패턴 또는 모델을 추출하는 것

학습 데이터를 잘 설명할 수 있는 패턴을 찾는 것

#### 오컴의 면도날

어떤 현상의 인과관계를 설명할 때 불필요한 가정을 삼가야 한다         
가능하면 학습 결과를 간단한 형태로 표현하는 것이 좋다

## 기계 학습의 종류

### 지도 학습

> 입력(문제)-출력(답)의 데이터들로부터 새로운 입력에 대한 출력을 결정할 수 있는 패턴 추출

답이 있으니까 정답지를 가지고 채점

### 비지도 학습

> 출력(답)에 대한 정보가 없는 데이터로부터 패턴 추출

답이 없기에 비교하여 채점

### 강화 학습

> 출력에 대한 정확한 정보는 제공하지 않지만,              
> $$<red>평가정보</red>는 주어지는 문제에 대해 각 상태에서의 행동을 결정
> $$<red>기대보상</red>이 최대가 되는 정책을 찾는 학습


# 지도학습

> 주어진 입출력이 모두 있는 데이터를 학습 데이터로 이용          
> 새로운 입력이 있을 때, 결과를 결정할 수 있도록 하는 방법을 찾아내는 것

## 분류

> 출력이 정해진 부류(class, category) 중의 하나로 결정            

학습 데이터를 잘 분류할 수 있는 함수를 찾는 것            
수학적 함수일 수도 있고, 규칙일 수도 있음        

### 분류기 학습 알고리즘

학습에 사용되지 않은 데이터에 대해서 분류를 잘하는 것이 목표            
일반화 능력이 좋아야 함           

- 결정트리 알고리즘
- KNN(K-근접이웃) 알고리즘
- 다층 퍼셉트론 신경망
- 딥러닝 신경망
- SVM, 서포트 벡터 머신
- AdaBoost, 에이다부스트
- 랜덤 포레스트
- 확률 그래프 모델


### 데이터의 구분

- 학습 데이터
    - 분류기를 학습하는데 사용하는 데이터 집합
    - 학습 데이터가 많을수록 유리
- 테스트 데이터
    - 학습된 모델의 성능을 평가하는데 사용하는 데이터 집합
    - 학습에 사용되지 않은 데이터
    - 출력에 대한 정보 O
- 검증 데이터
    - 학습 과정에서 학습을 중단할 시점을 결정하기 위해 사용하는 데이터 집합

### 과적합, Overfitting

> 학습 데이터에 대해서 지나치게 잘 학습된 상태
            
데이터는 오류나 잡음을 포함할 가능성이 크기 때문에,                         
학습 데이터에 대해 매우 높은 성능을 보이더라도                 
학습되지 않은 데이터에 대해 좋지 않은 성능을 보일 수 있음         

오히려 너무 학습데이터에 맞춰지면 전혀 다른 결과를 보일 수 있음

#### 회피 방법

학습 과정에서 별도의 검증데이터에 대한 성능 평가             
검증 데이터에 대한 오류가 감소하다가 증가하는 시점에 학습 중단          

![image](https://user-images.githubusercontent.com/32366711/137532597-344b605c-8327-4456-8494-50cc3f172b61.png){:width="500"}{:.aligncenter}


### 부적합, Underfitting

> 학습 데이터를 충분히 학습하지 않은 상태

### 분류기 성능 평가

#### 정확도, Accuracy

= 옳게 분류한 데이터 개수 / 전체 데이터 개수

얼마나 정확하게 분류하는가

테스트 데이터에 대한 정확도를 분류기의 정확도로 사용

학습 데이터와 테스트 데이터는 겹치지 않도록 해야함

#### 이진 분류기 성능 평가

[ROC-Curve](https://aristohyun.github.io/blog/2021/07/02/ROC-Curve/){: target="_ blank"}

|실제\\추측 | True | False |
|:---:|:---:|:---:|
|Positive|True Positive| <red>False Negative</red><br/><blue>Type II Error</blue>|   
|Negative|<red> False Positive</red><br /><blue> Type I Error </blue>|True Negative|    


@
\text{민감도} = \frac{TP}{TP+FN} \\\ 

\text{특이도} = \frac{TN}{FP+TN} \\\ 

\text{정밀도} = \frac{TP}{TP + FP} \\\ 

\text{음성 예측도} = \frac{TN}{TN + FN} \\\ 

\text{위 양성률} = \frac{FP}{FP + TN} \\\ 

\text{위 발견율} = \frac{FP}{TP + FP} \\\ 

\text{정확도} = \frac{TP + TN}{TP + FP + TN + FN} \\\ 

\text{F1 측도} = 2\frac{\text{정밀도} * \text{민감도}}{\text{정밀도} + \text{민감도}} \\\ 

@

#### ROC 곡선

> 부류 판정 임계값에 따른 그래프

- AUC
    - ROC 곡선에서 곡선 아래 부분의 면적
    - 0.5 ~ 1


### 데이터 부족 문제

#### K-fold Cross Validation

학습 데이터를 호율적으로 사용 가능

> 전체 데이터를 K등분 하여, 각 등분을 한번씩 테스트 데이터로 사용하여 성능 평가

![image](https://user-images.githubusercontent.com/32366711/137532901-ab7a4f80-b894-46cf-8cf3-a5067f66649b.png){:width="400"}{:.aligncenter}

### 데이터 불균형 문제

> Imbalanced Class Data            
> 특정 부류에 속하는 학습 데이터의 개수가 다른 부류에 비하여 지나치게 많은 경우

정확도에 의 한 성능 평가는 무의미할 수 있음

- $$<red>가중치</red>를 고려한 정확도 척도 사용               
- 많은 학습 데이터를 갖는 부류에서 <red>재 표본 추출</red>             
- 적은 학습데이터를 갖는 부류에 대해 <red>인공적인 데이터 생성</red>             


#### SMOTE

Synthetic Minority Over-Sampling Technique

빈도가 낮은 부류의 학습 데이터를 인공적으로 만들어내는 방법

1. 임의로 낮은 빈도 부류의 학습 데이터 x 선택
2. x의 KNN이 같은 부류의 데이터 선택
3. KNN중에 무작위로 데이터 y 선택
4. x와 y를 연결하는 직선상의 무작위 위치에 새로운 데이터 생성

![image](https://user-images.githubusercontent.com/32366711/137533370-112e987a-9a4f-44ef-9575-55290250c525.png){:width="400"}{:.aligncenter}


## 회귀

[회귀](https://aristohyun.github.io/blog/2021/06/25/Linear-Regression/){:target="_ blank"}

> 출력이 연속인 영역의 값 결정

기계학습의 회귀는
학습데이터를 가지고 연속인구간의 값이 나오도록 찾는것

이런 데이터를 가장 잘 근사할 수 있는 함수를 찾는 것

#### 오차

우리가 수집한 데이터는 항상 오차가 존재함

정규분포를 사용하는 이유가 그런 관점

$\text{(예측값 - 실제값)}^2$의 평균

@
E = \frac{1}{n} \sum \limits_{i=1}^{n} (y_ i - f(x_ i))^2
@

모델의 종류(함수의 종류)에 영향을 받음

### 경사하강법, Gradient descent method

> 오차 함수의 그레디언트 반대 방향으로 조금씩 움직여 가며 최적의 파라미터를 찾으려는 방법          
> 학습 데이터에 부합되는 출력값이 되도록 파라미터를 변경하는 일

@
E = \frac{1}{n} \sum \limits_{i=1}^{n} (y_ i - f(x_ i))^2 \\\ 
f(x) = ax + b \\\ 
\triangledown  E = (\frac{\partial E}{\partial a}, \frac{\partial E}{\partial b}) \\\ 
@
<br/>

각 파라미터별로 그레디언트를 계산하여 조정함

@
a \leftarrow a - \eta \frac{\partial E}{\partial a} \\\ 
b \leftarrow b - \eta \frac{\partial E}{\partial b}
@

### 과적합

> 지나치게 복잡한 모델 사용

모델의 복잡도를 성능 평가에 반영함(패널티)으로써 대응할 수 있음

### 부적합

> 지나치게 단순한 모델 사용

### 로지스틱 회귀

[로지스틱](https://aristohyun.github.io/blog/2021/07/01/Logistic-Regression/){: target="_ blank"}

> 주로 이진분류로 사용하는 회귀 모델

이진 분류는 0과 1의 값을 가져야 하는데,           
회귀모델은 $-\infty ~\infty $의 값을 가짐

따라서 로지스틱 함수를 이용하여 값의 범위를 바꿈

@
f(x) = \frac{1}{1 + e^{-\theta^T x}}
@

#### 가능도, likelihood

모델이 학습 데이터를 생성할 가능성

$
P(X) = \prod \limits_ {i=1}^{N} f(x_ i)^{y_ i}(1 - f(x_ i))^{1-y_ i} \\\ 
Log P = -\frac{1}{N} log P(X) = -\frac{1}{N} log P(X) = -\frac{1}{N} \sum \limits_ {i=1}^{N} (y_ i log f(x_ i) + (1-f(x_ i) log(1-y_ i))
$


### 오차의 편향과 분산 분해

오차의 기대값, $ E(Error) = \text{편향}^2 + \text{분산}$

편향 : 측정값과 예측값들의 평균과의 차이           
분산 : 예측값들의 분산                 


@
\begin{align\*}
E(Error) &= E\[ (f(x) - y)^2 \] \\\ 
 &= E\[ (f(x) -E\[f(x)\] +E\[f(x)\] - y)^2 \] \\\ 
 &= E\[ (E\[f(x)\]-y)^2 + 2(f(x) - E\[f(x)\])(E\[f(x)\] - y) + (f(x) - E\[f(x)\])^2 \] \\\ 
 &= E\[ (E\[f(x)\]-y)^2 \] + E\[ 2(f(x) - E\[f(x)\])(E\[f(x)\] - y)\] + E\[(f(x) - E\[f(x)\])^2 \] \\\ 
 &= (E\[f(x)\]-y)^2 + 2(E\[f(x)\] -y)E\[f(x) -E\[f(x)\] \]) + E\[(f(x) - E\[f(x)\])^2 \] \\\ 
 &= (E\[f(x)\]-y)^2 + E\[(f(x) -E\[f(x)\])^2 \] \\\ 
 &= bias^2 + variance
\end{align\*}
@

편향과 분산은 회귀 함수의 형태에 영향을 받음

#### 단순한 모델

- 큰 편향, 작은 분산
- 실제 데이터와 회귀 함수간 차이가 크며, 학습된 회귀 함수들 간의 차이는 적음

#### 복잡한 모델

- 작은 편향, 큰 분산
- 실제 데이터와 회귀 함수간 차이는 작고, 학습된 회귀 함수들 간의 차이는 큼

#### 트레이드 오프

편향은
- 단순한 모델로 잘못 가정할 때 크게 발생
- 부적합 문제 초래

분산은
- 복잡한 모델 사용에 따라 학습 데이터의 잡음으로 발생
- 과적합 문제 초래

![image](https://user-images.githubusercontent.com/32366711/137538571-e23c6769-9383-40c4-b527-fce0d147ed97.png){:.aligncenter}{:width="400"}


## 추천

> 개인별로 맞춤형 정보를 제공하려는 기술            
> 맞춤형 정보를 제공하여, 정보 검색의 부하를 줄여주는 역할

#### 희소 행렬

비어있는 부분을 채우는 것이 추천

![image](https://user-images.githubusercontent.com/32366711/137538761-29a4fe54-c9a8-4f42-b227-5355fba2792f.png){:.aligncenter}{:width="500"}


### 추천 기법

#### 내용 기반 추천

- 고객이 이전에 높게 평가했던 것과 유사한 내용을 갖는 대상을 추천
- 태그 및 카테고리 활용

#### 협력 필터링

- 사용자간 협력 필터링
    - 유사한 사용자간 집합을 이루어, 집합간 영화 추천
    - 유사한 사용자 A가 1번 영화를 좋아했다면 사용자 B도 좋아할 것
- 항목간 협력 필터링
    - 항목간의 유사도를 구하여 유사 항목 선택

#### 은닉 요소 모델

- 행렬 분해, 특이값 분해에 기반한 방법

![image](https://user-images.githubusercontent.com/32366711/137539080-2f9a569b-3834-4f42-9640-619f05b9e914.png){:.aligncenter}{:width="500"}



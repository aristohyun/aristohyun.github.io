---
layout: post
title: "AI, 2장 탐색과 최적화"
description: "AI, 이건명 교수님"
categories: [AI]
tags: [2021-2, AI, Artificial Intelligence, 이건명]
use_math: true
redirect_from:
  - /2021/09/06/
---

* Kramdown table of contents
{:toc .toc}      


# 탐색

## 상태 공간과 탐색

#### 탐색, search

> <blue>문제의 해(solution)[^solution]</blue>이 될 수 있는 것들의 <blue>집합</blue>을 <red>공간(space)</red>로 간주하고          
> 문제에 대한 <blue>최적의 해</blue>를 찾기 위해 <red>공간을 체계적으로 찾아 보는 것</red>               

#### 상태, state

> 특정 시점에 문제의 세계가 처해있는 모습

#### 세계, world

> 문제에 포함된 대상들과 이들의 상황을 포괄적으로 지칭

#### 상태 공간, state space

> 문제 해결 과정에서 초기 상태로부터 도달할 수 있는 <red>모든 상태들의 집합</red>           
> 문제의 해가 될 가능성이 있는 모든 상태들의 집합 

- 초기상태(initial state) : 문제가 주어진 시점의 시작 상태          
- 목표 상태(goal state) : 문제에서 원하는 최종 상태          

#### 상태 공간 그래프, state space graph

> 상태 공간에서 각 행동에 따른 상태의 변화를 나타낸 그래프

- 노드 : 상태
- 링크(엣지) : 행동

`일반적인 문제에서는 상태 공간이 매우 큼 -> 탐색 과정에서 그래프 생성`


![image](https://user-images.githubusercontent.com/32366711/134811678-4d87bc76-aee7-45d4-a44d-694df462b6bb.png){: width="500"}{: .aligncenter}


## 맹목적 탐색

> <red>정해진 순서</red>에 따라 상태 공간 그래프를 점진적으로 생성해 가면서 해를 탐색하는 방법

### 깊이 우선 탐색, Depth-First Search

방문한 노드는 재방문 하지 않음          
루트 노드에서 현재 노드까지의 경로 하나만 유지               

> 메모리 공간 사용이 효율적   
> 최단 경로 해의 탐색은 보장 불가                   

### 너비 우선 탐색, Breadth-First Search

모든 자식 노드를 확장하며 탐색           
전체 트리를 메모리에서 관리          

> 메모리 공간 사용 비효율           
> 최단 경로 해의 탐색을 보장함 

### 반복적 깊이 심화 탐색, Iterative-Deepening Search

깊이 한계가 있는 깊이 우선 탐색을 반복적으로 적용

> 최단 경로 해의 탐색을 보장                                   
> 메모리 공간 사용도 효율적        
> but, 반복적으로 깊이우선 탐색을 하다보니 시간적으로 비효율적                         
> 이지만, 실제로는 크게 늘지 않음[^iterative-deepening]                                                                

깊이 0에 대해 깊이 우선 탐색              
깊이 1에 대해 깊이 우선 탐색          
깊이 2, 깊이 3 ...                 
을 목표 상태를 찾을 때 까지 함                 


### 양방향 탐색, Bidirectional Search

초기 노드와 목적 노드에서 동시에 너비 우선 탐색을 진행          
반씩 나눠서 찾기에 깊이가 너비우선 탐색에 비해 반으로 줄음


## 정보이용 탐색

### 휴리스틱 탐색, Heuristic Search

> 그리스어 Εὑρίσκω (Eurisko, 찾다, 발견하다)         
> 시간이나 정보가 불충분하여 합리적인 판단을 할 수 없거나,          
> 굳이 체계적이고 합리적인 판단을 할 필요가 없는 상황에서 <red>신속하게 어림짐작 하는 것</red>

ex) 최단 경로 문제에서 목적지 까지 남은거리 == 지도상의 직선거리로 계산 (실제론 돌아갈지라도)

### 언덕 오르기 방법, Hill Climbing Method

> 지역 탐색 + 휴리스틱 탐색
> 현재 노드에서 휴리스틱에 의한 평가값이 가장 좋은 이웃 노드 하나를 확장해 가는 탐색 방법      

`국소 최적해`에 빠질 수 있음

![image](https://user-images.githubusercontent.com/32366711/134812658-7f881163-5cfa-4fe8-8adc-112527383d38.png){:width="500"}

### 최상 우선 탐색, Best-First Search

> 확장 중인 노드들 중에서 목표 노드까지 남은 거리가 <red>가장 짧은 노드를 확장</red>하여 탐색         
> 남은 거리를 정확히 모르니까 <blue>휴리스틱</blue> 사용

### 빔 탐색, Beam Search

> 휴리스틱에 의한 평가값이 우수한 <red>일정 개수의 확장 가능한 노드</red>만을        
> 메모리에 관리하면서 <red>최상 우선 탐색</red> 적용

### A* 알고리즘

> 추정한 전체 비용 $\hat f(n)$을 최소로 하는 노드를 확장해 가는 방법

- $f(n)$ : 노드 n을 경유하는 전체 비용
    - $f(n) = g(n) + h(n)$
    - 이미 투입된 비용 $g(n)
    - 목표까지 남은 비용 $h(n)$

- $h(n)$ : 남은 비용              
    - 정확한 예측 불가 -> 휴리스틱 함수 $\hat h(n)$ 사용

- $\hat f(n)$ : 노드 n을 경유하는 추정 전체 비용
    - $\textcolor{red}{\hat f(n) = g(n) + \hat h(n)}$


## 게임에서의 탐색

### 게임 트리, Grame Tree

> 상대가 있는 게임에서 자신과 상대방의 가능한 게임 상태를 나타낸 트리

![image](https://user-images.githubusercontent.com/32366711/134813332-de741d80-2ec9-4e21-abb3-7a54c81a8067.png){: width="500"}{: .aligncenter}

### mini-max 알고리즘

> 단말 노드부터 위로 올라가면서 최소-최대 연산을 반복하여 자신이 선택할 수 있는 방법 중 가장 좋은 것의 값으로 결정       

- Max 노드         
    - 자신에 해당하는 노드로 자기에게 유리한 최대값 선택

- Min 노드                   
    - 상대방에 해당하는 노드로 최소값 선택 

### $\alpha - \beta$ 가지치기, alpha-beta prunning

> 검토해 볼 필요가 없는 부분을 탐색하지 않는 것         
> 깊이 우선 탐색으로 제한 깊이 까지 탐색하면서
> Max 노드와 Min 노드의 값 결정

- alpha cut : Min 노드의 현재 값이 부모노드(Max)의 현재 값($\alpha$)보다 작으면 나머지 자식 노드 탐색 중지
    - $\alpha \geq V$ == 탐색 중지

- beta cut : Max 노드의 현재 값이 부모노드(Min)의 현재 값($\beta$)보다 크면 나머지 자식 노드 탐색 중지
    - $\beta \leq  V$ == 탐색 중지 


### 몬테 카를로 시뮬레이션, Monte Carlo Simulation, MCTS

> 지금 내가 유리하다면, 무작위로 수를 둬도 내가 유리할 것이다        

> 특정 확률 분포로 부터 무작위 표본을 생성하고         
> 이 표본에 따라 행동 과정을 반복하여 결과를 확인                 
> 이러한 결과 확인 과정을 반복하여 최종 결정을 하는 것

> 탐색 공간을 무작위 표본추출 하면서, 탐색트리를 확장하여         
> 가장 좋아 보이는 것을 선택 하는 휴리스틱 탐색 방법

선택 -> 확장 -> 시뮬레이션(MCTS) -> 역전파 의 단계를 반복           

![image](https://user-images.githubusercontent.com/32366711/134814859-4bfcb915-8326-414a-997f-157300202bcf.png){:width="500"}{: .aligncenter}

#### 선택, Selection

> 정책에 따라 자식 노드를 선택하여 단말 노드까지 내려감

- 가장 승률이 높은 루트의 자식 노드 선택
- 가장 빈번하게 방문한 루트의 자식 노드 선택
- 승률과 빈도가 가장 큰 루트의 자식 노드 선택
- 자식노드의 confidence bound값의 최소값이 가장 큰 루트의 자식 노드 선택 (UCB 정책)

`UCB 정책 (Upper Confidence Bound)`[^UCB]

@ \frac{Q(v')}{N(v')} + c \sqrt{\frac{2ln N(v)}{N(v')}} @



#### 확장, Expansion

> 선택된 단말 노드에서 트리 정책에 따라 노드 추가

#### 시뮬레이션, MCTS

> 기본 정책에 의한 몬테 카를로 시뮬레이션 적용             
> 무작위 선택 등의 방법으로 게임이 끝날 때까지 진행하여 결과 반환

#### 역전파, Backpropagation

> 반환된 결과를 루트 노드까지 올라가면서 승점 반영


### 알파고의 탐색

> 바툭판 형세 판단을 위한 한가지 방법으로 몬테카를로 트리 검색 사용             
> 단 무작위로 바둑을 두는 것이 아니라, 기보를 학습한 확장 정책망이라는 간단한 계산 모델을 사용          
> 가치망(딥러닝 신경망)을 함께 사용하여 형세 판단값을 계산함          

![image](https://user-images.githubusercontent.com/32366711/134815247-60b0251a-fcc6-4dc9-b7d2-6ce4aac29f7c.png)



## 제약조건 만족 문제

> 주어진 제약조건을 만족하는 조합 해(Combinatorial Solution)를 찾는 문제
> ex. 8-Queen 문제

### 백트랙킹 탐색, Backtracking Search

> 깊이 우선 탐색을 하는 것처럼 변수에 허용되는 값을 하나씩 대입

![image](https://user-images.githubusercontent.com/32366711/134815324-f0a999c8-d2bd-403e-97f7-a0fa7771aa90.png)


### 제약조건 전파, Constraint Progation

> 인접 변수 간의 제약 조건에 따라 각 변수에 허용될 수 없는 값들을 제거하는 방식

![image](https://user-images.githubusercontent.com/32366711/134815403-ec8d030d-5ade-43bc-a067-fec2e74b3b41.png)


# 최적화

> 여러 가지 허용되는 값들 중에서 주어진 기준을 가장 잘 만족하는 것을 선택하는 것


## 목적함수

> 최소 또는 최대가 되도록 만들려는 함수


## 조합 최적화, Combinatorial Optimization

> 순회 판매자 문제(TSP), 스케쥴링 문제 등과 같이               
> 주어진 항목들의 조합으로 해가 표현되는 최적화 문제           

- 순회 판매자 문제의 목적함수 : 경로의 길이, 경로가 최소가 되도록 하려고 함

### 유전 알고리즘, GA, Genetic Algorithm

> 생물의 <blue>진화를 모방</blue>한 집단 기반의 <red>확률적 탐색 기법</red>           
> 대표적인 <blue>진화 연산</blue>의 하나[^evolutinary_computation]

#### 생물의 진화

> 염색체의 유전자들이 개체 정보 코딩        

- 적자생존, fittest survival / 자연 선택, natural selection
    - 환경에 대한 적합도가 높은 개체의 높은 생존 및 후손 번성 가능성            
    - 우수 개체들의 높은 자손 증식 기회          
    - 열등 개체들도 작지만 증식 기회가 있음

- 집단의 진화
    - 세대 집단의 변화         

- 형질 유전과 변이
    - 부모 유전자들의 교차 상속
    - 돌연변이에 의한 변이

#### 생물 진화와 문제 해결

개체 <==> 후보 해, candidate solution

환경 <==> 문제, Problem

적합도 <==> 해의 품질, Qualty

![image](https://user-images.githubusercontent.com/32366711/134845436-b3f162bd-7bf3-4eec-ae56-e6a92c7a89c9.png){: width="350"}


- 후보해(candidate solution) 표현         
    - 염색체(chromosome) 표현

- 모집단(population)                              
    - 동시에 존재하는 염색체들의 집합

- 적합도 함수(fitness function)               
    - 후보해가 문제의 해로서 적합한 정도를 평가하는 함수

- 부모 개체 선택(selection)             
    - 높은 적합도의 개체가 새로운 개체를 생성할 확률이 높도록 함

- 유전 연산자(genetic operator)            
    - 새로운 개체 생성                
    - 교차(crossover) 연산자, 돌연변이(mutation) 연산자           

- 세대(generation) 교체
    - 엘리트주의(elitism) : 우수한 개체를 다음 세대에도 유지

![image](https://user-images.githubusercontent.com/32366711/134846201-b1f35072-a7d8-4bfa-a24f-35525aec5df0.png){: .aligncenter}{: width="500"}


#### 메타 휴리스틱, Meta Heuristics

> 최적해는 아니지만, 우수한 해를 빠르게 찾기 위한 <red>휴리스틱적인 문제해결 전략</red>

- 유전 알고리즘, Genetic Algorithm         
- 모방 알고리즘, Memetic Algorithm         
- 입자 군집 최적화, Particle Swarm Optimization, PSO              
- 개미 집단 알고리즘, Ant Coloy Algorithm          
- 타부 탐색, Tabu Search       
- 담금질 기법, Simulated Annealing            
- 하모니 탐색, Harmonic Search           
- 유전 프로그래밍, Genetic Programming

## 함수 최적화

> 어던 목적 함수(objective Function)가 있을 때,      
> 이 함수를 최대/최소로 하는 변수 값을 찾는 최적화 문제      

![image](https://user-images.githubusercontent.com/32366711/134846529-9b8cfddf-1c8b-4035-b2a7-eb74c8907e22.png)

### 경사 하강법, Gradient Descent Method        

> 복잡한 함수인 경우, 임의의 위치에서 시작하여       
> 함수 $f(x)$의 그레디언트(gradient)[^gradient] 반대 방향을 조금씩 움직여 가며        
> 최적의 변수 값을 찾으려는 방법        

탐색 중, 매 위치에서 그레디언트를 계산하여         
반대 방향으로 이동하도록 변수의 값을 반복적으로 조금씩 조정                      

@f(x) = f(x1,x2), \bigtriangledown f = (\frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2})     \\\ 
x_1 \leftarrow x_1 - \eta \frac{\partial f}{\partial x_1}          \\\ 
x_2 \leftarrow x_2 - \eta \frac{\partial f}{\partial x_2}
@


### 제약조건 최적화, Constrained Optimization

> 제약조건을 만족하면서 목적 함수를 최적화 하는 변수들의 값을 찾는 문제
> SVM(Support Vector Machine)의 학습에서 사용

![image](https://user-images.githubusercontent.com/32366711/134848181-771d62fc-4cce-4aca-8551-218bc615af02.png){: width="400"}

#### 라그랑주 함수, Lagrange

> 제약조건들과 목적함수를 결합한 함수

[^solution]: 일련의 동작으로 구성되거나 하나의 상태로 구성                
[^iterative-deepening]: 자식당 10개의 자식 노드를 가질 때 약 11%정도 추가 노드를 생성함    
[^UCB]: v : 부모노드 ,  v' : 자식노드 ,  N(v') : 방문 횟수 ,  Q(v') : 점수(이긴 횟수)
[^evolutinary_computation]: Evolutinary Computation, 유전 알고리즘, 유전 프로그래밍, 진화 전략 등이 있음       
[^gradient]: 각 변수에 대해 편미분한 벡터           

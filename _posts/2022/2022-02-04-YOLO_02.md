---
layout: post
title: "YOLO, Code Review" 
description: "YOLO, You Only Look Once"
categories: [DeepLearning]
tags: [DeepLeaning, YOLO, Object Detection]
use_math: true
redirect_from:
  - /2022/02/04
---

* Kramdown table of contents
{:toc .toc} 

# YOLO Code

`Roboflow로부터 데이터셋 다운로드`
~~~ python

from roboflow import Roboflow
rf = Roboflow(api_key="my_key")
project = rf.workspace().project("bccd-554xa")
dataset = project.version(1).download("yolov5")
~~~

`하이퍼 파라미터 파일로 관리`

~~~ yaml
%%writetemplate /content/yolov5/models/custom_yolov5s.yaml

# parameters
nc: {num_classes}  # number of classes
depth_multiple: 0.33  # model depth multiple
width_multiple: 0.50  # layer channel multiple

# anchors
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# YOLOv5 backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Focus, [64, 3]],  # 0-P1/2
   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
   [-1, 3, BottleneckCSP, [128]],
   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
   [-1, 9, BottleneckCSP, [256]],
   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
   [-1, 9, BottleneckCSP, [512]],
   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
   [-1, 1, SPP, [1024, [5, 9, 13]]],
   [-1, 3, BottleneckCSP, [1024, False]],  # 9
  ]

# YOLOv5 head
head:
  [[-1, 1, Conv, [512, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 6], 1, Concat, [1]],  # cat backbone P4
   [-1, 3, BottleneckCSP, [512, False]],  # 13

   [-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 4], 1, Concat, [1]],  # cat backbone P3
   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)

   [-1, 1, Conv, [256, 3, 2]],
   [[-1, 14], 1, Concat, [1]],  # cat head P4
   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)

   [-1, 1, Conv, [512, 3, 2]],
   [[-1, 10], 1, Concat, [1]],  # cat head P5
   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)

   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]
~~~

`train.py 코드를 이용하여 모듈의 학습 진행`

~~~ python
# train yolov5s on custom data for 100 epochs
# time its performance
%%time
%cd /content/yolov5/
!python train.py --img 416 --batch 16 --epochs 100 --data {dataset.location}/data.yaml --cfg ./models/custom_yolov5s.yaml --weights '' --name yolov5s_results  --cache
~~~

- batch : 전체 데이터 중에서 학습에 사용할 갯수
- epochs : 모든 데이터들이 전체 신경망을 왕복하는 횟수

ex) 전체 1000 크기의 데이터를 batch size 100으로 나누었을때 10개의 그룹이 생김. 

10개의 데이터 그룹이 전체 신경망을 10번 돌면 epoch 10

~~~
Epoch   gpu_mem       box       obj        cls     total   targets  img_size
0/99     1.78G     0.09456   0.1566    0.03446    0.2856       218       416: 100% 48/48 [00:26<00:00,  1.79it/s]
         Class      Images  Targets          P         R    mAP@.5  mAP@.5:.95: 100% 3/3 [00:03<00:00,  1.25s/it]
           all          73      967      0.353     0.322    0.0237     0.00506
                 
Epoch   gpu_mem       box       obj        cls      total   targets  img_size
99/99     1.8G    0.03122     0.107  0.0008246      0.139       295       416: 100% 48/48 [00:20<00:00,  2.29it/s]
        Class      Images   Targets          P          R    mAP@.5  mAP@.5:.95: 100% 3/3 [00:03<00:00,  1.01s/it]
          all          73       967      0.866      0.892     0.912     0.613
~~~

오차율이 감소한 것을 볼 수 있음

~~~ 

# 훈련된 모델을 통해 detect.py로 이미지 디텍팅
!python detect.py --weights runs/train/yolov5s_results/weights/best.pt --img 416 --conf 0.4 --source BCCD-1/test/images

# 라벨링된 이미지 출력
import glob
from IPython.display import Image, display

for imageName in glob.glob('/content/yolov5/runs/detect/exp2/*.jpg'): #assuming JPG
    display(Image(filename=imageName))
    print("\n")
    
~~~
          
<img width="325" alt="image" src="https://user-images.githubusercontent.com/32366711/152950105-b5da2252-c6d4-453b-9666-d7264290a0f3.png">
<img width="334" alt="image" src="https://user-images.githubusercontent.com/32366711/152950138-dbea75f5-25f8-496e-b1b9-48dc82f352f8.png">

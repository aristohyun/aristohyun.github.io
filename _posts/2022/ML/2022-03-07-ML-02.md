---
layout: post
title: "ML, 2장 분류"
description: "기계학습, 이건명교수님"
categories: [MachineLearning]
tags: [2022-1, Machine Learning, ML, 이건명]
use_math: true
redirect_from:
  - /2022/03/07
---

* Kramdown table of contents
{:toc .toc} 

# 지도학습

> 주어진 입출력에 대한 데이터 이용 : 학습 데이터     
새로운 입력이 있을 때 결과를 결정할 수 있도록 하는 방법을 찾아내는 것

# 분류

> 데이터들을 정해진 몇 개의 부류(class)로 대응시키는 문제

- 분류 문제의 학습
  - 학습 데이터를 잘 분류할 수 있는 함수를 찾는 것
  - 함수의 형태는 수학적 함수일 수도 있고, 규칙일 수도 있음
- 분류기(classifier)
  - 학습된 함수를 이용하여 데이터를 분류하는 프로그램

인공지능을 이용한 결정을 내렸을 때, 왜 그런 결정을 내렸는지 설명을 해야할 이유가 생기고 있으며, 이런 설명기능이 중요해지고 있다. 다른 알고리즘은 블랙박스기에 이런 설명이 어렵지만, 결정트리의 경우 그나마 할수있다

> 학습에 사용되지 않은 데이터에 대해서 분류를 잘 하는 것이 이상적인 분류기 
> 즉, 일반화(generalization) 능력이 좋은 것



## 분류 알고리즘

- 결정트리(decision tree) 
- 로지스틱 회귀(logistic regression) 
- K-근접이웃 (K-nearest neighbor, KNN) 
- 서포트 벡터 머신(Support Vector Machine, SVM)
- 앙상블 모델
  - 에이다부스트(AdaBoost), 랜덤 포리스트(random forest), Gradient Boosting, XGBoosting, Light Boosting, CatBoost
- 확률 그래프 모델 (probabilistic graphical model) 
- 다층 퍼셉트론 신경망
- 딥러닝(deep learning) 신경망

## 분류와 데이터

- 학습 데이터(training data, 훈련데이터)
  - 분류기(classifier)를 학습하는데 사용하는 데이터 집합
  - 학습 데이터가 많을 수록 유리
- 테스트 데이터(test data)
  - 학습된 모델의 성능을 평가하는데 사용하는 데이터 집합
  - 학습에 사용되지 않은 데이터
- 검증 데이터(validation data)
  - 학습 과정에서 학습을 중단할 시점을 결정하기 위해 사용하는 데이터 집합

## 과적합과 부적합

- 과적합
  - 학습 데이터에 대해서 <blue>지나치게 잘 학습된 상태</blue>
  - 데이터는 <red>오류나 잡음</red>을 포함할 개연성이 크기 때문에, 학습 데이터에 대해 매우 높은 성능을 보이더라도 학습되지 않은 데이터에 대해 좋지 않은 성능을 보일 수 있음
- 부적합
  - 학습 데이터를 충분히 학습하지 않은 상태

### 과적합 회피 방법

학습을 진행할 수록 오류가 개선은 되지만, 지나치게 학습이 진행되면 과적합 발생

학습과정에서 별도의 <blue>검증 데이터</blue>(validation data)에 대한 성능 평가

검증 데이터에 대한 오류가 감소하다가 증가하는 시점에 학습 중단. 조기 종료(early stopping) 

- 학습 데이터 규모 확대
- 모델 복잡도 축소
  - 단순한 모델 사용
- 규제화(regularization) 기법 적용
  - Ridge 규제화, Lasso 규제화
- 학습 알고리즘에 따른 기법 적용
  - 신경망 – dropout

### 부적합 회피 방법

- 모델 복잡도 증가
- 사용할 특징 개수 확대
- Feature engineering 수행
  - 특징 선택, 특징 추출 등
- 학습 데이터 품질 개선
  - 잡음 제거
- 학습 회수(epoch) 증가

## 분류기의 성능 평가

**정확도 (accuracy)**

> 얼마나 정확하게 분류하는가

정확도 = (옳게 분류한 데이터 개수)/(전체 데이터 개수) 

- 테스트 데이터에 대한 정확도를 분류기의 정확도로 사용
- 정확도가 높은 분류기를 학습하기 위해서는 많은 학습데이터를 사용하는 것이 유리

`학습데이터와 테스트 데이터는 겹치게 않도록 해야 함`

#### 데이터가 부족하다면?

학습 데이터로도 부족한데, 테스트 데이터를 별도로 구할 수 없다면

**K-겹 교차 검증**

- 전체 데이터를 k 등분
- 각 등분을 한번씩 테스트 데이터로 사용하여, 성능 평가를 하고 평균값 선택

15p k-fold cross-validation

**Leave-One-Out**

k fold를 데이터 갯수만큼 나눈 것

즉 1개의 데이터에 대해서 테스트를 해본다


#### 불균형 부류 데이터 문제

> 특정 부류에 속하는 학습 데이터의 개수가 다른 부류에 비하여 지나치
게 많은 경우, 정확도에 의한 성능 평가는 무의미할 수 있음

A 부류의 데이터가 전체의 99%인 경우, 무조건 A 부류라고 말하면 정확도는 99%가 됨

- 가중치를 고려한 정확도 척도 사용
- 많은 학습데이터를 갖는 부류에서 재표본추출(re-sampling, undersampling) 
- 적은 학습데이터를 갖는 부류에 대해서 인공적인 데이터 생성

##### SMOTE 알고리즘

`Synthetic Minority Over-sampling Technique`

> 빈도가 낮은 부류의 학습 데이터를 인공적으로 만들어 내는 방법

1. 임의로 닞은 빈도 부류의 학습 데이터 𝒙 선택
2. 𝒙의 k-근접이웃(k-nearest neighbor, KNN)인 같은 부류의 데이터 선택
3. k-근접이웃 중에 무작위로 하나 𝑦를 선택
4. 𝑥와 𝑦를 연결하는 직선 상의 무작위 위치에 새로운 데이터 생성

19p smote

### 이진 분류기 성능 평가

혼동행렬, confusion matrix


- 민감도(sensitivity)[^sensitivity]
  - $ \text{민감도} = \frac{TP}{TP + FN} $
- 특이도(specificity)[^specificity]
  - $ \text{특이도} = \frac{TN}{FP + TN} $
- 정밀도(precision)[^precision]
  - $ \text{정밀도} = \frac{TP}{TP + FP} $
- 음성 예측도
  - $ \text{음성 예측도} = \frac{TN}{TN + FN} $
- 위양성율
  - 위양성율 = 1 - 특이도
  - $ \text{위양성율} = \frac{FP}{FP + TN} $
- 위발견율
  - $ \text{위발견율} = \frac{FP}{TP + FP} $
- 정확도
  - $ \text{정확도} = \frac{TP + TN}{TP + FP + TN + FN} $
- F1 측도
  - $ \text{F1} = 2\frac{\text{정밀도} * \text{민감도}}{\text{정밀도} + \text{민감도}} $

[^sensitivity]: 실제로 양성인것 중에 양성이라고 예측한 것. 재현율(recall)/진양성율(true positive rate) 

[^specificity]: 실제로 음성인것 중에 음성이라고 예측한 것. 진음성율(true negative rate) 

[^precision]: 양성이라고 예측한것 중에, 진짜로 양성인 것



ROC 모든 임계값에 대한 민감도와 위양성율에 대한 그래프

ROC는 원래 이진분류에서 사용하는데,
만약에 다중클래스라면?

클래스 A일떄와 아닐때, B일때와 아닐때로 각각 다그려줌


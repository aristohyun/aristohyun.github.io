---
layout: post
title: "ML, 1장 기계학습의 소개"
description: "기계학습, 이건명교수님"
categories: [MachineLearning]
tags: [2022-1, Machine Learning, ML, 이건명]
use_math: true
redirect_from:
  - /2022/03/03
---

* Kramdown table of contents
{:toc .toc} 


# 기계학습

> 경험을 통해서 나중에 유사하거나 같은 <red>일(task)</red>를 더 효율적으로 처리할 수 있도록 시스템의 <red>구조나 파라미터를 바꾸는 것</red>


> 컴퓨터가 데이터로부터 특정 문제해결을 위한 지식을 자동으로 추출해서 사용할 수 있게 하는 기술

직접 만든 규칙이나 휴리스틱은 복잡하며, 성능이 불충분한데 반면,

기계학습 방법은 자동으로 분류 규칙이나 프로그램을 생성하며, 더 뛰어난 성능을 보인다.

`귀납적 학습` 학습 데이터를 잘 설명할 수 있는 패턴을 찾는 것


#### 오컴의 면도날, Occam's razor

> 어떤 현상의 인과관계를 설명할 때 불필요한 가정을 삼가야 한다    
> 가능하면 학습 결과를 <red>간단한 형태</red>로 표현하는 것이 좋다


# 기계학습의 종류

데이터가 많은경우 딥러닝이 띄어난 성능을 보일 수 있으나, 그 데이터가 적으면 과적합 문제가 생길수 있다

## 지도학습 Supervised Learning

> 입력(문제)-출력(답)의 데이터들로 부터 새로운 입력에 대한 출력을 결정할 수 있는 패턴 추출

### 분류

> 출력이 정해진 모델(부류, 범주) 학습

- 결정트리
- 앙상블 모델(Random Forest, Gradiant Boosting, 
XGBoosting, CatBoosting, Light GBM)
- 로지스틱 회귀
- KNN
- SVM
- Naïve Bayesian
- 분류 딥러닝 모델 등

### 회귀

> 출력이 연속구간의 값인 함수 학습

- 선형회귀
- 리지(ridge), 라소(Lasso) 회귀
- 일래스틱 넷(Elastic Net) 
- RANSAC, 이소토닉(Isotonic) 회귀 
- 다항 회귀 
- 서포트 벡터회귀(SVR, Support Vector Regression) 
- KNN


## 비지도학습 Unsupervised Learning

> 출력에 대한 정보가 없는 데이터로 부터 패턴 추출

### 군집화 (clustering) 

> 유사한 것들의 집단 식별

- k-means algorithm, 계층적 군집화, 스펙트럼(spectral) 군집화, DBSCAN 등

### 차원 축소(dimensionality reduction) 

> 고차원에서 표현된 데이터를 저차원으로 표현

- PCA(Prinicipal Component Analysis), t-SNE, 오토인코더(autoencoder) 등

### 밀도 추정 (density estimation) 

> 관측된 데이터로 부터 데이터를 생성한 확률 분포 추청

- 가우시안 혼성 모델(Gaussian Mixture Model), 히스토그램 등

### 이상치 탐지 (outlier detection) 

> 다른 데이터와 크게 달라서 비정상으로 의심되는 데이터 탐지

오차와는 다름. 유의미한 값이기에 분석이 필요로한 값

### 연관규칙 마이닝 (association rule mining) 

> 속성 값간의 관계 식별

- A Priori, FP-Growth, Eclat 등

### 토픽 모델링(topic modeling)

- 문서들에서 주제 식별
- 문서별 주제 식별

## 강화학습 Reinforcement Learning


> 출력에 대한 정확한 정보를 제공하지는 않지만, 평가정보(reward)는 주어지는 문제에 대해 각 상태에서의 행동(action)을 결정


>  문제에 대한 직접적인 답을 주지는 않지만 경험을 통해 <red>기대 보상(expected reward)</red>이 최대가 되는 <red>정책(policy)</red>을 찾는 학습

정책 : 각 상태 별로 취할 행동을 정해 놓은 것


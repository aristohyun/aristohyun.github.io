---
layout: post
title: "ML, 10장 DNN, CNN, RNN"
description: "기계학습, 이건명교수님"
categories: [MachineLearning]
tags: [2022-1, Machine Learning, ML, 이건명]
use_math: true
redirect_from:
  - /ML/10
  - /blog/ML/10
---

* Kramdown table of contents
{:toc .toc} 


# DNN

> 딥러닝이란, DNN 기반의 기계 학습 기법을 차별화 하여 일겉는 말

`다수의 층`, 을 갖는 신경망 구조 사용 == 멀티레이어 퍼셉트론

일반 신경망은 데이터에서 직접 특징을 추출해 만든 특징 벡터를 신경망 모델 학습을 위한 입력으로 사용하기에 특징 추출(특징 벡터)가 큰 영향을 미친다

그러나 딥러닝 신경망은 특징 추출과, 모델 생성 학습을 함께 수행. 즉 데이터로부터 문제해결에 효과적인 특징을 학습을 통해 추출한다

## 기울기 소멸 문제

> 은닉층이 많은 다층 퍼셉트론에서 층을 거칠수록 오차가 크게 줄어 학습이 되지 않는 현상

완전히 해결할 순 없지만, 완화 할 수 있다. `RelU`

~~~ python
def ReLU(x):
    return np.maximum(0,x)
~~~

![image](https://user-images.githubusercontent.com/32366711/173880798-035788b4-4fba-4294-8879-060e97bbf159.png)


## 가중치 초기화
 
> 가중치 초기화는 신경망의 성능에 큰 영향을 주는 요소

보통 초기값으로 0에 가까운 무작위 값을 사용한다

-> 개선된 방법으로 다음의 방법을 사용하기도 한다

- 균등 분포 초기화
  - $U\[ -\sqrt{\frac{6}{n_ i + n _ {i+1}}}, \sqrt{\frac{6}{n_ i + n _ {i+1}}} \]$ 에서 무작위로 선택
- 제이비어 초기화
  - $\frac{N(0,1)}{\sqrt{n_ i}}$ 에서 무작위로 선택
- 허 초기화
  - $\frac{N(0,1)}{\sqrt{n_ i / 2}}$ 에서 무작위로 선택


~~~ python
# 균등 분포 초기화
sd = sd.sqrt(6/(layer_size[i+1]+ layer_size[i])) 
W = np.random.uniform(-sd, sd, layer_size[i]* layer_size[i-1]).reshape(layer_size[i+1], layer_size[i])

# 제이비어 초기화
W = np.random.randn(layer_size[i+1], layer_size[i]) * np.sqrt(1/layer_size[i])

# 허 초기화
W = np.random.randn(layer_size[i+1], layer_size[i]) * np.sqrt(2/layer_size[i])
~~~

## 과적합 문제

> 모덱이 학습 데이터에 지나치게 맞추어진 상태

학습 데이터는 잡음과 오류를 포함하고 있기에 학습되지 않는 데이터에 대해 성능 저하가 생긴다

완화 방법
- 규제화
- 드롭아웃
- 배치 정규화

### 규제화 기법, regulaization

> 오차 함수를 `오차`항과 `모델 복잡도` 항으로 정의

모델이 복잡해지면 과적합이 되므로, 모델 복잡도를 패널티항으로 추가한다

신경망 학습에서는 절대값이 큰 가중치에 패널티를 부여한다
-> 릿지, 라소 정규화

### 드롭아웃

> 학습할 때, 무작위로 노드를 선택해 가중치 연결을 하지 않음

미니 배치나 학습주기마다 드롭아웃할 노드들을 새롭게 선택하여 학습힌다

추론을 할 때는 드롭아웃을 하지 않고, 전체 학습된 신경망을 사용하여 출력을 계산한다

~~~ python
if dropOut == True:
  for j in range(self.nh): # 은닉층의 각 노드에서
    p = self.rnd.random() # [0,0, 1.0) 의 범위의 무작위 값을 가진다
    if p < 0.2: # 만약 0.2 미만이면 
      self.dNodes[j] = 1 # 드롭아웃 할것임을 표기
    else:
      self.dNodes[j] = 0

for k in rnage(self.no): # 각 출력노드
  for j in range(self.nh): # 각 은닉노드
    if dropOut == True and self.dNodes[j] == 1: # 위에서 드롭아웃 할것임을 정의했다면
      continue
    oSums[k] += self.hNodes[j] * self.hoWeights[j,k]
  oSums[k] += self.oBiases[k]
~~~

### 가중치 갱신 전략

![image](https://user-images.githubusercontent.com/32366711/173880863-d3e9eec9-aefa-4d70-97d3-8d1820a0b6f9.png)


- 학습 주기, 에포크, epoch
  - 전체 데이터에 대해서 신경망 모델을 한번 학습하는 것
- 배치, batch
  - 가중치를 한번 수정할 때 사용되는 데이터
  - 배치크기 = 하나의 배치에 포함되는 데이터 개수
- 반복, iteration
  - 한번 학습주기를 완료하기 위해 수행되는 배치의 처리 횟수
  - iteration 개수 = 전체데이터 / 배치크기 = 미니배치 개수

#### 확률적 갱신

> 한번에 하나의 학습 데이터에 대한 그레디언트를 계산하여 가중치를 갱신

가중치 변동이 심해서 성능 개선이 저하되는 단점이 있다

~~~ python
for i in range(epoch):
  for one_data in training_data: 
    gradient = evaluate_gradient(one_data)
    weight = weight - learning_rage * gradient # 경사하강법
~~~


#### 배치 갱신

> 전체 학습 데이터에 대한 그레디언트 평균을 구해서 가중치를 갱신

학습 속도가 느리다

~~~ python
for i in range(epoch):
  gradient = evaluate_gradient(one_data)
  weight = weight - learning_rage * gradient # 경사하강법
~~~

#### 미니배치 갱신

> 일정 개수의 학습 데이터, 미니 배치에 대해 그레디언트의 평균을 구해 가중치를 갱신한다

과적합 문제 완화에 가장 도움이 된다


~~~ python
for i in range(epoch):
  for one_batch in get_mini_batches(training_data, one_batch_size = 32):
    gradient = evaluate_gradient(one_data)
    weight = weight - learning_rage * gradient # 경사하강법
~~~

### 배치 정규화 기법

> 신경망의 각 층에서 미니배치 b의 각 데이터에 가중치 연산을 적용한 결과는 $x_ i$의 분포를 정규화 하는 것

![image](https://user-images.githubusercontent.com/32366711/173880953-efe27937-bf0e-45fd-b835-4d3cbecc6064.png)

내부 공변량 이동 문제[^internal_covariate_shift]를 해결하기 위해 도입

미니 배치 B에 대해
1. $x_ i$의 평균 $\mu_ B$가 0이 되고 표준편차 $\sigma_ B$는 I가 되도록 변환
2. 크기조정 파라미터 $\gamma$와 이동 파라미터 $\beta$ 적용
3. 변환된 데이터 $y_ i$ 생성

- 미니 배치 평균 = $\mu_ B = \frac{1}{m} \sum \limits_ {i=1}^{m}x_ i$
- 미니 배치 분산 = $\sigma^2_ B = \frac{1}{m} \sum \limits_ {i=0}^{m}(x_ i - \mu_ B)^2\$
- 정규화 = $\hat{x_ i} = \frac{x_ i - \mu_ B}{\sqrt{\sigma^2_ B + \epsilon}}$
- 크기조정 및 이동 변환 = $y_ i = \gamma \hat{x_ i} + \beta$

#### 학습

미니배치 B에 대해 평균과 표준편차를 구해서 학습 데이터로 변환

#### 추론

- 각 미니배치 $B_ i$의 평균 $\mu_ {B_ i}$와 분산 $\sigma^2_ {B_ i}$의 평균을 구해서 저장
- 지수감소 이동평균을 사용해 계산
  - $\mu \leftarrow \alpha \mu + (1-\alpha)\mu_ {B_ i}$
  - $\sigma ^2 \leftarrow  \alpha \sigma^2 + (1-\alpha)\sigma_ {B_ i}$
  - $\alpha$ = 모멘텀 계수 (0.9 , 0.99)
- 저장된 평균과 표준편차를 사용한 학습 데이터 변환


[^internal_covariate_shift]: 이전 층들의 학습에 의해 이들 층의 가중치가 바뀌게 되면, 현재 층에 전달되는 데이터의 분포가 현재 층이 학습했던 시점의 분포와 차이 발생 ==> 학습 속도 저하

## 가중치 학습 기법

![image](https://user-images.githubusercontent.com/32366711/173881001-b426fead-37c8-4478-a95a-82d83adbd402.png)

### 경사 하강법

$
w^{t+1} = w^t - \eta \frac{\partial E(w^t)}{\partial w}
$

### 모멘텀 사용 경사 하강법

$
\Delta^ t = \alpha \Delta^{t-1} + \eta \frac{\partial E(w^t)}{\partial w} \\\ 
w^{t+1} = w^t -  \Delta^t 
$

![image](https://user-images.githubusercontent.com/32366711/173881041-711e7257-b9ba-4f8e-a6d5-428474cbec69.png)

### NAG

$
\Delta^ t = \alpha \Delta^{t-1} + \eta \frac{\partial E(w^t - \alpha \Delta^{t-1})}{\partial w} \\\ 
w^{t+1} = w^t -  \Delta^t 
$

![image](https://user-images.githubusercontent.com/32366711/173881059-29c821f2-559a-4b2e-9497-463238080138.png)

### Adagrad

가중치 별로 다른 학습률 사용해 스텝의 크기를 조절함

$
g_ i ^ t = \frac{\partial E(w^t)}{\partial w_ i} \\\ 
G_ i ^ t = G_ i ^ {t-1} + (g_ i ^ t)^2 \\\ 
w_ i ^ {t+1} = w_ i ^ t - \frac{\eta}{\sqrt{G_ i ^ t + \epsilon }} g_ i ^ t
$

### Adadelta

Adagrad의 확장으로, 이전 그레디언트의 영향을 점점 줄이며 그레디언트 제곱합을 계산함

![image](https://user-images.githubusercontent.com/32366711/173881087-f9f21bb9-35ba-453c-87d8-222555048145.png)

### RMSprop

가중치별 다른 학습률 사용

결합된 그레디언트 제곱의 합의 제곱근을 학습률로 사용

![image](https://user-images.githubusercontent.com/32366711/173881114-70816b0f-3ff2-49e7-a29f-7df017e6023d.png)


### ADAM

가중치별 다른 학습률 사용

그레디언트의 1차, 2차 모멘텀 사용

![image](https://user-images.githubusercontent.com/32366711/173881188-8c4ee870-5101-47b6-ada7-fbf1a8b7d735.png)

### AdaMax

Adam에서 학습률의 분모에 나타나는 $\hat{v}^t$는 L2 norm을 사용하여 계산하는데

AdaMax 에서는 infinity norm인 max를 사용하여 계산

![image](https://user-images.githubusercontent.com/32366711/173881208-cb34ac32-5e89-4a23-a071-945fe57baedc.png)


### AdamW

L2 norm과 가중치 감소 방법을 함께 적용한 Adam

![image](https://user-images.githubusercontent.com/32366711/173881234-e0be1b6a-6786-40ef-b530-a75b4aa4aee0.png)


# CNN

> 컨볼루션 신경망, 동물의 시각피질의 구조에서 영감을 받아 만들어진 딥러닝 신경망 모델

> They also make strong and mostly correct assumptions about the nature of images (namely, stationarity of statistics and locality of pixel dependencies)

- 전반부 : 컨볼루션 연산을 통해 특징 추출 `컨볼루션`
- 후반부 : 특징을 이용해 분류 `다층퍼셉트론`

영상 분류, 문자 인식 등 인식문제에 높은 성능을 보인다

~~~ python
conv = Conv2D(X, W, w0, p=(0,0), s=(1,1))
~~~

## 컨볼루션

> 일정 영역의 값들에 대해 가중치를 적용하여 하나의 값을 만드는 연산

입력 * 컨볼루션 필터 커널(마스크) = 컨볼루션 결과

#### 스프라이드

커널을 다음 컨볼루션 연산을 위해 이동시키는 칸 수

#### 패딩

컨볼루션 결과의 크기를 조절하기 위해 입력 배열의 둘레를 확장하고 0으로 채우는 연산

#### 특징 지도, feature map

> 컨볼루션 필터의 적용 결과로 만들어지는 2차원 행렬

특징지도의 원소 값 == 컨볼루션 필터에 표현된 특징을 대응되는 위치에 포함하고 있는 정도

k개의 컨볼루션 필터를 적용하면 k개의 2차원 특징지도가 생성된다

### 종류

#### 다중 채널의 2D 컨볼루션

![image](https://miro.medium.com/max/1400/1*Emy_ai48XaOeGDgykLypPg.gif)

![image](https://miro.medium.com/max/1400/1*5otecXBNlms3lslqlYworA.gif)

![image](https://user-images.githubusercontent.com/32366711/173885490-70eb192b-7647-4f16-9561-73e47d8301bc.png)

![image](https://miro.medium.com/max/1400/1*Emy_ai48XaOeGDgykLypPg.gif)

![image](https://miro.medium.com/max/1400/1*5otecXBNlms3lslqlYworA.gif)

![image](https://user-images.githubusercontent.com/32366711/173885490-70eb192b-7647-4f16-9561-73e47d8301bc.png)

#### 1 * 1 컨볼루션

- 효율적인 저차원 임베딩, 피쳐 풀링
- 컨볼루션 후 다시 비선형성 적용

![image](https://user-images.githubusercontent.com/32366711/173885512-faacd09f-db78-4662-8948-1f582c9492dd.png)

- 효율적인 저차원 임베딩, 피쳐 풀링
- 컨볼루션 후 다시 비선형성 적용

![image](https://user-images.githubusercontent.com/32366711/173885512-faacd09f-db78-4662-8948-1f582c9492dd.png)

#### 디컨볼루션

입력보다 큰 출력이 생성됨

![image](https://user-images.githubusercontent.com/32366711/173885564-4b330252-f866-4a3c-9c74-d879fc1998d4.png)


#### 팽창 컨볼루션

- 커널 크기를 늘리지 않고 출력 단위의 수용 필드를 저렴하게 늘리는 데 사용되며, 이는 여러 개의 확장 된 컨볼루션이 차례로 쌓일 때 특히 효과적입니다.

![image](https://miro.medium.com/max/790/1*niGh2BkLuAUS2lkctkd3sA.gif)
![image](https://user-images.githubusercontent.com/32366711/173885612-a2529e88-19c1-48fa-933e-2910dcacc913.png)

- 커널 크기를 늘리지 않고 출력 단위의 수용 필드를 저렴하게 늘리는 데 사용되며, 이는 여러 개의 확장 된 컨볼루션이 차례로 쌓일 때 특히 효과적입니다.

![image](https://miro.medium.com/max/790/1*niGh2BkLuAUS2lkctkd3sA.gif)
![image](https://user-images.githubusercontent.com/32366711/173885612-a2529e88-19c1-48fa-933e-2910dcacc913.png)

#### 분할 컨볼루션

**깊이별 분할 컨볼루션**
![image](https://user-images.githubusercontent.com/32366711/173885801-3be52f11-4ac0-4998-a26b-5151dcf92cbe.png)

**공간 분할 컨볼루션**
![image](https://user-images.githubusercontent.com/32366711/173885666-16ffdc61-dac5-4137-93bf-d1c175274138.png)

**평탄화 컨볼루션**
![image](https://user-images.githubusercontent.com/32366711/173885726-ae955596-a9de-4ed1-9223-7ab2a196b76c.png)


#### 집단 컨볼루션

![image](https://user-images.githubusercontent.com/32366711/173885971-c4c1b1e3-367e-4de3-8036-275228bb2bff.png)


#### 채널 섞기 집단 컨볼루션, Shuffled Grouped Convolution

![image](https://user-images.githubusercontent.com/32366711/173885993-59990a78-ba7b-4370-b3f7-42409223184d.png)


## 풀링

> 일정 크기의 블록을 통합하여 하나의 대푯값으로 대체하는 연산

- 최대값 풀링
  - 지정된 블록 내의 원소들 중에서 최대값을 대표값으로 선택
- 평균값 풀링
  - 블록내의 원소들의 평균값을 대표값으로 선택
- 확률적 풀링
  - 블록내의 각 원소가 크기에 비례하는 선택 확률을 갖도록 하고, 이 확률에 따라 원소를 선택
  - 학습시에는 확률적 풀링
  - 추론시에는 확률적 가중 합 사용

> 풀링은 중간 연산 과정에서 만들어지는 특징지도들의 크기를 축소한다

크기가 축소되어 다음 단계에서 사용될 메모리 크기와 계산량이 감소하게 된다

보통 특징들을 결합하거나, 위피 변화에 강건한 특징들을 선택한다

~~~ python
def maxPooling(mat, K, L):
  M, N = mat.shape
  MK = M // K
  NL = N // L
  return mat[:MK*K, :NL*L].reshape(MK,K,NL,L).max(axis=(1,3))
~~~

## 컨볼루션 신경망의 구조

- 특징 추출을 위한 컨볼루션
  - Conv 층 : 컨볼루션 연산
  - ReLU
  - Pooling(선택)
- 추출된 특징을 사용하는 다층 퍼셉트론 부분(분류, 회귀 수행)
  - FC층 반복(Fully connected)
  - 분류의 경우 마지막 층에 소프트맥스를 하는 SM 연산 추가 (확률로 보기 위함)

ex) Conv - ReLU - Pool -  Conv - ReLU - Pool - FC - FC - SM

#### 알렉스넷의 가중치 개수와 메모리 요구량

![image](https://user-images.githubusercontent.com/32366711/173886033-a705bfcd-2545-43cd-92b7-bb7ef635ee47.png)

### 가중치 학습

`자동 미분`

> 함수를 기본 연산의 제어 흐름으로 나타내서, 각 기본 연산의 도함수를 사용해 연쇄 법칙에 의해 미분값을 계산


## 물체 인식 CNN 모델

### LeNet

> 5계층 구조, Conv - Pool - Conv - Pool - Conv - FC - FC - (SM)

32 * 32 필기체 숫자 영상인 MNIST 데이터를 입력으로 손글씨를 인식하는 모델

- 풀링 : 가중치 * (2*2 블록 합) + 편차항
- 활성화 함수 : 시그모이드

### AlexNet

> 8계층 구조, Conv-Pool-Norm-Conv-Pool-Norm-Conv- Conv-Conv-Pool-FC-FC-FC(SM)

- 활성화 함수로 ReLU 함수를 사용한 첫 모델
- 최대값 풀링 사용
- FC 층에 드롭아웃 기법 사용

### VGGNet

> 16계층, 19 계층

- 모든 층에서 3*3 필터 사용
- 3 * 3 필터를 2회 적용하면 5 * 5 필터를 적용한 것과 같은 효과를 보이며, 3번 적용하면 7 * 7 필터를 적용한것과 같은 효과를 보인다
  - 그러나 3번 적용하면 27개의 가중치를 계산해야 하지만, 7 * 7 필터는 49개의 가중치를 계산해야 하므로
  - 계산 횟수도 적고, ReLU를 3번 적용함으로써 더 복잡한 결정 경계를 표현할 수도 있다

### GoogleNet

> 22개 층, 인셉션 모듈을 이용

![image](https://user-images.githubusercontent.com/32366711/173886096-370d944e-64b7-4600-8669-b0b2773339b4.png)

- 인셉션 모듈이란 직전 층의 처리 결과에서 1 * 1, 3 * 3, 5 * 5 컨볼루션을 적용하는 것
- 여러 크기의 특징들을 동시에 추출한다

![image](https://user-images.githubusercontent.com/32366711/173886155-ffbf551e-e924-4d03-9812-a3e859efe899.png)


1 * 1 컨볼루션은 동일한 위치의 특징지도 값을 필터의 가중치와 선형결합 하는 역할을 한다.    
이 필터의 개수를 조절해 출력되는 특징 지도의 개수를 조절할 수 있다

- 22계층 모델이지만, AlexNet 모델에 비해 가중치 개수는 10%만 증가했다
- 기울기 소멸 문제를 완화하기 위해 보조 분류기를 추가
  - 보조 분류기를 통해 그레디언트 정보를 제공한다

### ResNet

> 152개층 모델
![image](https://user-images.githubusercontent.com/32366711/173886223-5f33e879-e1f1-4270-8939-b5b54256c08f.png)

- 다수의 층을 사용함으로써 상위 계층에서 의미있는 특징 추출이 가능하다
- 그러나 기울기 소멸 문제가 발생할 수 있다

이에 `잔차 모듈`을 도입

- 기대하는 출력과 유사한 입력이 들어오면 영벡터에 가까운 값을 학습한다
  - 즉 입력의 작은 변화에 민감하고, 잔차를 학습하게 된다
- 다양한 경로를 통해 복합적인 특징 추출이 가능하다
  - 필요한 출력이 얻어지면 다른 컨볼루션 층을 건너뛸 수 있다
  - 따라서 다양한 조합의 특징 추출이 가능하다


### DenseNet

> 각 층은 모든 앞 단계에서 올 수 있는 지름길 연결을 구성한다        
> 배치 정규화 - ReLU - Conv(3*3)

![image](https://user-images.githubusercontent.com/32366711/173886483-4dab4b2b-73c2-4828-9f28-d60a48895072.png)

![image](https://user-images.githubusercontent.com/32366711/173886517-cd034fdc-ee03-4532-a1c7-46a87521df72.png)

- 특징 지도의 크기를 줄이기 위해 풀링 연산 적용
- 밀집 블록과 전이 층으로 구성하여 전이 층에서 크기를 줄임

![image](https://user-images.githubusercontent.com/32366711/173886409-1886c8bc-f5ae-4c75-8a8e-b611f6a8abef.png)

### DPN (Dual Path Network)

> ResNet + DenseNet

- ResNet
  - 이전 단계의 동일한 특징 정보가 각 단계에 전달되어 이들 특징을 재사용 하도록 하는 방식
  - 상대적으로 이전 단계의 특징들로부터 새로운 특징을 만드는 것에는 소극적임
- DenseNet
  - 새로운 특징이 추출될 가능성이 높음
  - 그러나 이전에 추출된 특징이 다시 추출될 가능성도 높음

> 마이크로 불록에서 둘의 특징을 결합

![image](https://user-images.githubusercontent.com/32366711/173886577-05241f72-4429-4541-9ab8-6550814dee62.png)

### SENet 

> 기존 CNN 모델에 SE 블록을 삽입해 사용

![image](https://user-images.githubusercontent.com/32366711/173886614-8cf7d867-9e8e-4d66-9884-e31375472794.png)

#### SE 블록

> 채널 간의 상호의존성을 모델링하여 채널별 특징 반응을 적응적으로 재조정함

- 압축(squeeze) 연산
  - 채널 별 통계량 계산을 위해 전역 평균 풀링을 수행
  - $z_ c = F_ {sq} (u_ c) = \frac{1}{H x W}\sum \limits_ {i=1}^{H} \sum \limits_ {j=1}^{W} u_ c (i, j)$
- 흥분(excitaion) 연산
  - 임베딩을 입력으로 가져와서 채널별로 변경된 가중치들을 생성하는 self-gating 방식
  - $s = F_ {ex}(z, W) = \sigma(g(z,W)) = \sigma(W_ 2 \delta(W_ 1, z))$
  - $\bar{x_ c} = F_ {scale}(u_ c, s_ c) = s_ c u_ c$

### MobileNet

> 컴퓨팅 자원 제약이 있는 환경을 위한 CNN 모델            
> 배치 정규화와 ReLU를 포함한 깊이별 분할 컨볼루션

깊이별 분할 컨볼루션 = 깊이별 컨볼루션 + 위치별 컨볼루션 사용

따라서 계산할 가중치가 줄어든다

![image](https://user-images.githubusercontent.com/32366711/173886792-895db8ab-029d-4581-ba26-66cd77701e87.png)

#### 계산 비용

입력 F = $D_ F * D_ F * M$
출력 G = $D_ F * D_ F * N$

- $D_ F$ = 특징지도의 폭과 넓이
- $D_ K$ = 커널(필터)의 폭과 넓이 
- M = 입력 깊이
- N = 출력 깊이

**표준 컨볼루션 층**

- 컨볼루션 필터 = $D_ K * D_ K * M * N$
- 전체 계산 비용 = $D_ K D_ K M D_ F D_ F D_ F$

**깊이별 분할 컨볼루션**

- 전체 계산 비용 = $D_ K D_ K M D_ F D_ F + M N D_ F D_ F$

### SuffleNet 

> 컴퓨팅 자원 제약이 있는 모바일 단말기를 위한 모델

정확도 유지 및 계산 비용 축소

위치별 집단 컨볼루션 + 채널 섞기 연산 사용

![image](https://user-images.githubusercontent.com/32366711/173886876-befd71d9-4c24-4a22-be5a-25dd5a5f995e.png)

### MnasNet

> 모바일 단말기에 사용가능한 구조를 자동으로 찾는 기법으로 찾은 모델

AutoML의 한 분야

하이퍼파라미터도 자동으로 찾으려고 노력함
그런 API도 제공하고있음
= 그리디 탐색, 정해준것중에 랜덤으로, 그냥 무작위로 하기도 함

하이퍼파라미터 최적화, 옵티미제이션

AutoML은 어떤 알고리즘이든. 그 알고리즘의 파라미터를 구하려고 함

### YOLO

> 객체 영역과 객체 인식(분류)를 동시에 수행
<<<<<<< HEAD
<<<<<<< HEAD

=======
>>>>>>> bd1ee20 (Update 2022-05-09-ML-10.md)
=======

>>>>>>> c0e7bee (Update 2022-05-09-ML-10.md)
![image](https://user-images.githubusercontent.com/32366711/173886933-b973f4a9-17b5-4799-a9ee-852727cb5a84.png)

7 * 7 그리드, 그리드 별 30차원의 벡터를 이용

- 그리드 별 2개의 경계 상자와 확신도 정보를 추출해 벡터에 저장
  - (x, y, w, h, C), (x, y, w, h, C) == 총 10칸
  - 그리드 내 중심 좌표 (x,y) 
  - (x,y)를 중심으로 하는 박스의 크기(w, h)
  - 해당 그리드내의 객체가 각 부류(20개)일 확률 

#### 경계 상자의 신뢰도

IOU를 이용해 확신도 계산

#### 비 최대치 압축 : NMS

불필요한 경계 상자를 제거하며,       
해당 부류의 경계 상자가 다른 경계상자와의 IOU 값이 임계값 이상이면, 확률 값이 작은 것을 제거

따라서 경계상자별 부류 하나를 결정함

#### 손실함수

![image](https://user-images.githubusercontent.com/32366711/173995634-17eacd10-4d28-4cfc-80fd-7a75c570b81f.png)

### U-Net 

> 이미지 영역 분할을 위한 모델

![image](https://user-images.githubusercontent.com/32366711/173886993-198c1f3f-ed37-44dc-bc3a-a060c3bebbba.png)


## 전이 학습

> 큰 규모의 딥러닝 신경망을 학습시킬 때는, 많은 학습 데이터와 상당한 학습 시간이 필요

- ImageNet 데이터를 학습한 여러 컨볼루션 신경망 모델이 공개되어 있음
- 공개된 모델을 이용해 누구나 적용, 활용 가능

> 학습된 컨볼루션 신경망의 컨볼루션 층들을 가져오고,      
> 뒤 단계에서 분류하는 다층 퍼셉트론 모델을 붙여서 학습할 수 있다

![image](https://user-images.githubusercontent.com/32366711/173887038-f3ea041c-5645-4945-87c6-547c085c3c28.png)

# RNN

> 재귀 신경망, 순환 신경망

$h_ t = tanh(h_ {t-1} W_ h + x_ t W_ x + b)$

#### 서열 데이터란

- 음성, 자연어, 문장, 동영상, 주가 변동 등의 데이터에서
- 구성 요소가 순차적으로 발생하거나, 구성요소 간에 순서가 존재하는 데이터
- 즉 이전 값들이 현재 값에 영향을 주는 것

> 서열 데이터의 분류 예측에서는 현재 시점의 값과 이전 시점의 값들을 고려해야 한다        

기계 번역, 음성 인식, 필기체 인식, 영상 주석, 동영상 행동 인식, 작사 작곡 등 다양한 분야에서 활용 중

## 재귀 신경망의 구조와 동작

![image](https://user-images.githubusercontent.com/32366711/173888427-849be162-48d5-47ff-bf51-52b9a5ed8ed6.png)


### 재귀 신경망의 구조

> 기본적으로 은닉층 한개와 출력층으로 구성

그러나 입력의 일부로 과거의 정보를 반영하기 위해 은닉층/출력층의 값을 입력의 일부로 재사용

### 재귀 신경망에서 입력과 출력의 대응 형태

![image](https://user-images.githubusercontent.com/32366711/173888372-19812253-30ed-43a7-95d8-c740410d0117.png)

- (a) 각 시점의 입력에 대한 출력이 학습 데이터에 지정
  - 언어 모델, 품사 태깅
- (b) 앞 시점에 입력이 끝나면 출력이 주어지는 상황
  - 기계적 번역
- (c) 일련의 데이터가 입력으로 주어진 다음, 마지막에 결과 값이 주어지는 상황
  - 감성 분석
- (d) 하나의 입력에 대해 일련의 출력이 나오는 것
  - 영상에 주석 달기

### Code

~~~ python
def forward(self, X): # X 입력
  s = torch.mm(X, self.U) + torch.mm(self.h, self.W) + self.b
  self.h = torch.tanh(s) # 재귀 신경망 
  o = torch.mm(s, self.V) + self.c
  f = F.softmax()
  return f, self.h # output, hidden
~~~ 

## 재귀 신경망의 학습

### 재귀 신경망의 학습 데이터 형태

> 서열 데이터의 집합

### BPTT 알고리즘

> Back Propagation Through Time          
> 과거 시간으로 오차를 전달하여 가중치를 조정

과거 시점으로 오차를 전달할 때 각 가중치 U, W, V는 동일하게 사용한다

학습을 할 때는, 각 시점에서의 그레디언트를 구한 다음, 그 평균을 해당 변수에 대한 그레디언트로 사용한다

![image](https://www.goldenplanet.co.kr/data/data/2021/11/2021-11-11_16-33-12-50935-1636615992.png)

![image](https://user-images.githubusercontent.com/32366711/173888472-f74f0293-bc70-40c5-973d-192663575f75.png)

- 목표 출력 서열 = $y' = (y_ 0 ', \cdots , y_ N ')$
- RNN 출력 서열 = $y_ t = (y_ {t1}, \cdots, y_ {tK})$(`one hot vector`)
- 오차 함수
  - 분류 = $E_ t (y_ t, y_ t ') = - \sum \limits_ {i=1}^{K} y_ {yi} ' log y_ {ti} $  `교차 엔트로피`
  - 회귀 = $E_ t (y_ t, y_ t ') = \frac{1}{K} \sum \limits_ {i=1}^{K} (y_ {yi} ' - y_ {ti})^2 $
- 목적 함수 
  - $E(y, y') = \sum \limits_ {t}^{} E_ t (y_ t, y_ t ')$
- 목적 함수의 그레디언트 
  - $\frac{\partial E}{\partial W} = \sum \limits_ {i}^{} \frac{\partial E_ t(y_ t, y_ t ')}{\partial W}$

t = 3 일 때 W 에 대한 그레디언트
 $\frac{\partial E_ 3}{\partial W}$
![image](https://user-images.githubusercontent.com/32366711/173995985-d9e43903-3297-49bb-bbb5-39e151ae4441.png)

t = 3 일 때 V 에 대한 그레디언트
$\frac{\partial E_ 3}{\partial V} = \frac{\partial E_ 3}{\partial y_ 3} \frac{\partial y_ 3}{\partial V} = \frac{\partial E_ 3}{\partial y_ 3} \frac{\partial y_ 3}{\partial z_ 3} \frac{\partial z_ 3}{\partial V} $

t = 3 일 때 U 에 대한 그레디언트
$\frac{\partial E_ 3}{\partial U} = \sum \limits_ {k=0}^{3} \frac{\partial E_ 3}{\partial y_ 3} \frac{\partial y_ 3}{\partial h_ 3} \frac{\partial h_ 3}{\partial h_ k} \frac{\partial h_ k}{\partial U}$


## BPTT 알고리즘 그레디언트

[설명 영상](https://www.youtube.com/watch?v=BwmddtPFWtA)
<<<<<<< HEAD
<<<<<<< HEAD
=======
=======

>>>>>>> 499581d (Update 2022-05-09-ML-10.md)
![image](https://user-images.githubusercontent.com/32366711/173888616-695d33bd-70f8-4077-823f-75c415a54336.png)

![image](https://user-images.githubusercontent.com/32366711/173888670-eaf1bf91-cfee-42a4-97ba-328160f6c016.png)

![image](https://user-images.githubusercontent.com/32366711/173888752-c935f0b9-b248-4d8c-8906-57f546210e59.png)

![image](https://user-images.githubusercontent.com/32366711/173888802-323c1966-d37a-4b64-bd57-c49590987adf.png)

![image](https://user-images.githubusercontent.com/32366711/173888878-35bd449e-588f-4db5-899e-de3eedc8581e.png)

![image](https://user-images.githubusercontent.com/32366711/173888903-30c5c52d-0456-4e31-b28d-885d53bde880.png)

![image](https://user-images.githubusercontent.com/32366711/173888951-b2bfc1ac-c226-4c6d-9d00-2353f6d7ff73.png)

![image](https://user-images.githubusercontent.com/32366711/173888970-88d7e7f9-4813-46e1-bbc4-1aa70d61de18.png)
>>>>>>> 06c6060 (Update 2022-05-09-ML-10.md)

![image](https://user-images.githubusercontent.com/32366711/173888616-695d33bd-70f8-4077-823f-75c415a54336.png)

<<<<<<< HEAD
![image](https://user-images.githubusercontent.com/32366711/173888670-eaf1bf91-cfee-42a4-97ba-328160f6c016.png)

![image](https://user-images.githubusercontent.com/32366711/173888752-c935f0b9-b248-4d8c-8906-57f546210e59.png)

![image](https://user-images.githubusercontent.com/32366711/173888802-323c1966-d37a-4b64-bd57-c49590987adf.png)

![image](https://user-images.githubusercontent.com/32366711/173888878-35bd449e-588f-4db5-899e-de3eedc8581e.png)

![image](https://user-images.githubusercontent.com/32366711/173888903-30c5c52d-0456-4e31-b28d-885d53bde880.png)

![image](https://user-images.githubusercontent.com/32366711/173888951-b2bfc1ac-c226-4c6d-9d00-2353f6d7ff73.png)

![image](https://user-images.githubusercontent.com/32366711/173888970-88d7e7f9-4813-46e1-bbc4-1aa70d61de18.png)


=======
>>>>>>> 06c6060 (Update 2022-05-09-ML-10.md)
## 재귀 신경망의 기울기 소멸과 폭발

행렬의 고유값 분해로 $W^{100}$ 등을 계산 가능

고유값 < 1 이면 기울기 소멸
고육밧 > 1 이면 기울기 폭발

### 기울기 소멸 문제

> 오차 정보를 역전파 시키는 과정에서 그레디언트가 급격히 영벡터에 가까워져 학습이 되지 않는 현상

일부 가중치 성분에서만 발생이 가능하기에 문제 발생을 파악하기 어렵다

### 기울기 폭발 문제

> 학습 과정에서 그레디언트가 급격히 커지는 현상

일부 성분의 기울기 폭발 현상은 다른 성분에도 영향을 미치기에 문제 발생을 확인하기 쉽다



## 기울기 폭발 문제의 대응 방법

### RMSprop 방법 사용

> 최근 그레디언트들의 크기 평균에 해당 하는 값으로 나누어 사용

### 단기 BPTT 사용 (truncated BPTT)

> 오차 정보를 최근의 몇 단계까지만 역전파

가중치 행렬 W이 거듭제곱 되는 횟수를 계산

### 그레디언트 최대값 고정 방법 사용

> 그레디언트가 일정한 임계값 이상이 되면 임계값으로 고정

$\|\| \bigtriangledown f \|\| > \theta$ 면 $ \bigtriangledown f \leftarrow \theta \frac{\bigtriangledown f}{\|\| \bigtriangledown f \|\|}$

## 재귀 신경망의 제약

### 일반 재귀 신경망의 입력에 대한 민감도

> 시점 t=1 에서의 입력에 대한 시점별 민감도를 노드의 진하기로 보인 것

시간이 진행됨에 따라 새로운 입력이 은닉 상태에 바연영되기 때문에 과거의 기억은 점차 사라진다

![image](https://user-images.githubusercontent.com/32366711/173889237-8afde7e9-3276-480e-8e7f-d9f9ad7171e2.png)

### 게이트 장착을 통한 민감도 조절

> 게이트의 조작을 통해 먼 시점까지 영향 전파가 가능

`LSTM`은 게이트의 동작을 학습을 통해 결정한다

## LSTM 재귀 신경망

> 역전파되는 그레디언트가 쉽게 소멸되는 현상을 완화시키는 RNN 모델

각 은닉 노드가 상태 저장소와 저장, 출력, 망각을 조절하는 게이트를 포함한다

![image](https://user-images.githubusercontent.com/32366711/173889321-fce431d5-aec0-4eba-8741-59118d078d13.png)


### LSTM 재귀 신경망의 동작

$
h_ 0 \leftarrow 0 \\\ 
c_ 0 \leftarrow 0 \\\ 
for t = 1 to T \\\ 
\;\;\;\;  i_ t \leftarrow \sigma(U_ i x_ t + W_ i h_ {t-1} + b_ i) \\\ 
\;\;\;\;  a_ t \leftarrow tanh(U_ c x_ t + W_ c h_ {t-1} + b_ c) \\\ 
\;\;\;\;  f_ t \leftarrow \sigma(U_ f x_ t + W_ f h_ {t-1} + b_ f) \\\ 
\;\;\;\;  c_ t \leftarrow i_ t \circ a_ t + f_ t \circ c_ {t-1} \\\ 
\;\;\;\;  o_ t \leftarrow \sigma(U_ o x_ t + W_ o h_ {t-1} + V_ o c_ {t-1} + b_ f) \\\ 
\;\;\;\;  h_ t \leftarrow o_ t tanh(c_ t)
$

### LSTM 재귀 신경망의 학습

- BPTT 사용
- 게이트와 상태 저장소에 대한 오차함수 E의 그레디언트를 계산해서 사용

## GRU 재귀 신경망

> 상태 저장소, 리셋 게이트, 갱신 게이트를 포함하는 모델

### GRU 재귀 신경망 학습

- BPTT 알고리즘 사용
- LSTM 재귀 신경망의 파라미터 개수의 약 3/4을 포함
- LSTM 재귀 신경망과 유사한 성능

# Transformer 모델

> 서열 데이터 처리를 위한 attention 기반의 인코더-디코더 모델          
> RNN을 사용하지 않고 sequenve to sequenve 모델 구현

`자연어 처리`에서 CNN 모델의 역할을 하는 우수한 모델

병렬 처리가 가능하며 RNN에 비해 처리시간이 개선되었다

## 자기 주목

[설명 링크](https://towardsdatascience.com/illustrated-self-attention-2d627e33b20a)

![image](https://user-images.githubusercontent.com/32366711/173889412-89b817e7-6413-423f-aebd-a34e5d5f884e.png)


## BERT

> transformer의 `인코더` 부분을 사용한 언어 모델
> Bi-directional transformer 로 구성

잘 학습된 BERT 언어모델에 1개의 classification layer를 부착하여 다양한 NLP task를 수행한다

- 두 개의 문장을 입력으로 사용
- 문장을 WordPiece 토큰화 하여 사용

![image](https://user-images.githubusercontent.com/32366711/173889596-c2a23424-f511-4c6a-a6ae-a70696e7e26e.png)


## GPT

> transformer의 `디코더` 블록을 이용한 언어 모델

![image](https://user-images.githubusercontent.com/32366711/173889622-a10fd0aa-c202-492d-8764-5b6504904038.png)


# PyTorch

~~~ python
import torch

torch.Tensor() # Numpy 배열로 된 데이터를 PyTorch에서 다룰 수 있는 텐서로 변환
torch.LongTensor() # LongTensor로 변환
TensorDataSet() # 배열 쌍을 대응되는 원소끼리 결합해 하나의 데이터 집합 생성
TensorLoader(tensorDataset, batch=64, shuffle=True) # dataset을 학습 및 추론에 사용하기 편리한 객체로 변환
~~~

## 계산 그래프

> 연산 과정을 data flow로 나타낸 그래프 구조

그레디언트 계산은 Computation graph를 이용해 체인 룰을 적용한다

<<<<<<< HEAD
<<<<<<< HEAD
![image](https://user-images.githubusercontent.com/32366711/173894468-eecb34e7-5355-4763-bfb8-94540f86c674.png)
=======
10-5 이미지 9
>>>>>>> bd1ee20 (Update 2022-05-09-ML-10.md)
=======
![image](https://user-images.githubusercontent.com/32366711/173894468-eecb34e7-5355-4763-bfb8-94540f86c674.png)
>>>>>>> 06c6060 (Update 2022-05-09-ML-10.md)

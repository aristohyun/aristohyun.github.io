---
layout: post
title: "ML, 9장 신경망 1"
description: "기계학습, 이건명교수님"
categories: [MachineLearning]
tags: [2022-1, Machine Learning, ML, 이건명]
use_math: true
redirect_from:
  - /ML/11
  - /blog/ML/11
---

* Kramdown table of contents
{:toc .toc} 


# 신경망
 
> 신경망(neural network, artificial neural network)             
> 인간 두뇌에 대한 계산적 모델을 통해 인공지능을 구현하려는 분야


신경망 안에 딥뉴럴네트워크가 있음

한 뉴런의 축색돌기 끝과 다른 뉴런의 수상돌기가 맞닿아 있는것을 신경연접이라고 함

이미지 3


# 퍼셉트론

> 로젠블랏이 제안한 학습가능한 신경망 모델

입력신호에 가중치를 주어 출력값을 조절하는 방식

@
s = \sum \limits_ {i=1}^{d} w_ i x_ i + b = \sum \limits_ {i=0}^{d} w_ i x_ i
@

이미지 4 + 활성화함수

~~~ python
# 간단한 뉴런 하나의 계산
def Perceptron(inputs):
    sum = np.dot(inputs, weights[1:]) + weights[0]
    if sum > 0:
        activation = 1
    else:
        activation = 0
    return activation
~~~

#### OR 연산

이미지 6

@
y = f(s) = f(\sum \limits_ {i=1}^{2} w_ i x_ i + b ) = x_ 1 + x_ 2 - 0.5
@

#### AND 연산

@
y = f(s) = f(\sum \limits_ {i=1}^{2} w_ i x_ i + b ) = x_ 1 + x_ 2 - 1.5
@

## 문제점

선형 분리가능문제만 해결할 수 있음 (3차원일땐 면)
-> 선형 분리불가 문제, 간단한 XOR문제도 해결 못하더라



# 다층 퍼셉트론

> 여러 개의 퍼셉트론을 층 구조로 구성한 신경망 모델

이미지 8

OR 뉴런과 NAND 뉴런을 AND 뉴런으로 합치면 XOR 완성

-> 파라미터를 자동으로 결정할 방법이 없다       
-> 학습을 시킬 수 없다          

학습?

입력-출력 ($x_ i$, $y_ i$ )의 학습 데이터에 대해서, 기대출력 $y_ i$와 다층 퍼셉트론의 출력 $f(x_ 𝑖)$의 차이, 즉 오차(error)가 최소가 되도록 가중치 $w$를 결정하는 것 

학습 가능한 다층 퍼셉트론 
그러면 오차 역전파(error backpropagation) 알고리즘을 써보자
활성화 함수를 계단 함수에서 미분가능한 시그모이드 함수로 대체 
경사 하강법 적용 

## 활성화 함수

#### 계단
~~~ python
def step(x):
    if x > 0:
        return 1
    else:
        return 0
~~~

#### 시그모이드

@
\begin{align\*}
\sigma(x,a) &= \frac{1}{1 + e^{-ax}} \\\ 
\sigma'(x,a) &= a\sigma(x,a)(1-\sigma(x,a))
\end{align\*}
@

~~~ python
def sigmoid(x, a=1):
    return 1/(1+np.exp(-a*x))

def d_sigmoid(x, a=1):  # 미분값을 따로 계산할 필요가 없다
    return a*sigmoid(x,a)*(1 - sigmoid(x,a))
~~~

#### 쌍곡 탄젠트함수

@
\begin{align\*}
\tanh(x,a) &= \frac{e^{2x} - 1}{e^{2x} + 1} \\\ 
\tanh'(x,a) &= 1 - tanh^2(x)
\end{align\*}
@

~~~ python
def tanh(x):
    return (np.exp(2*x)-1)/(np.exp(2*x)+1)

def d_tanh(x):
    return 1.0-tanh(x)*tanh(x)
~~~

## 동작

이미지 12

# 미분

> 함수 𝑓(𝑥)의 변수 𝑥에 대한 순간변화율     
> 𝑥의 아주 미세한 변화에 대한 𝑓(𝑥)의 변화량     

@
f'(x) = \frac{d f(x)}{dx} = \underset{lim}{\triangle x \rightarrow 0} \frac{f(x + \triangle x) - f(x)}{\triangle x}
@

## 연쇄 법칙 Chain Rule

## 편미분

> 다변수 함수에 대하여, 그 중 `하나의 변수`에 주목하고 나머지 변수의 값을 고정시켜 놓고 그 변수에 대해 하는 미분 

## 다변수 함수의 연쇄 법칙

## 그레디언트

어느방향으로 얼마나 커지는가

오차가 최소가되는 값을 찾아야하니까 그레디언트 반대방향으로

# 다층 퍼셉트론의 학습

-> `오차 역전파 알고리즘`

22p 이미지

입력 노드 d개를 통해 히든 노드 1개(j)의 값을 구할 수 있음. 이렇게 히든 노드 총 p개를 구함
$
zsum_ j = \sum \limits_ {i=1}^{d} u_ {ji} x_ i + u_ {j0} \\\ 
z_ j = f(zsum_ j)
$

입력값 x와 가중치 u의 곱의 총합 (zsum)을 구한 후 활성화 함수를 거쳐(f(zsum)) 노드 z의 값을 얻을 수 있음

히든 노드 p개를 통해 출력 노드 1개(j)의 값을 구할 수 있음. 이렇게 총 출력 노드는 m개를 구함

$
osum_ k = \sum \limits_ {j=1}^{p} v_ {kj} z_ j + v_ {k0} \\\ 
$

마찬가지로 노드 z를 x처럼, 가중치 v를 가중치 u 처럼 생각해        
osum과 출력값 o를 구할 수 있음

이렇게 임의의 가중치를 통해 예측값 o를 구했으면, 원래 출력값인 y와 비교해 오차(오차 제곱합)를 구할 수 있음

$
E = \frac{1}{2} \sum \limits_ {k=1}^{m} (o_ k - y_ k)^2
$

다음의 오차함수를 통해 그레디언트 디센트 방식을 통해 가중치를 조정하려함.

$
v^{t+1} = v^{t} - \eta \frac{\partial E}{\partial v} \\\ 
u^{t+1} = u^{t} - \eta \frac{\partial E}{\partial u}
$

다음의 오차함수의 v의 미분값과 u의 미분값만 구하면 됨

다음을 구하기 위해 체인룰을 적용

먼저 오차부터 역으로 오는 것이기에 v에 대해 먼저 계산해야 하는데          
p개의 z마다 m개의 v가 있음. j번째 z의 ($z_ j$) k번째 가중치($v_ kj$)에 대해서 오차역전파를 계산하려고 한다면, (k번째 가중치로 생성되는 결과는 $o_ k$, 모든 z의 k번째 가중치와의 곱의 합)

$
\frac{\partial E}{\partial v_ {kj}} = \frac{\partial E}{\partial o_ k} \frac{\partial o_ k}{\partial v_ {kj}} \\\ 
\frac{\partial E}{\partial o_ k} = \frac{\partial}{\partial o_ k} \frac{1}{2} \sum \limits_ {k=1}^{m} (o_ k - y_ k)^2 = o_ k - t_ k \\\ 
\frac{\partial o_ k}{\partial v_ {kj}} = \frac{\partial}{\partial v_ {kj}} \sum \limits_ {j=1}^{p} v_ {kj} z_ j + v_ {k0}  = z_ j * f'(osum_ k) \\\ 
\therefore \frac{\partial E}{\partial v_ {kj}} = (o_ k - t_ k) * z_ j * f'(osum_ k)
$

마찬가지로 d개의 x마다 p개의 u가 있음. i번째 x의 ($x_ i$) j번째 가중치($u_ ji$)에 대해서 오차역전파를 계산하려고 한다면, (j번째 가중치로 생성되는 결과는 $z_ j$, 모든 x의 j번째 가중치와의 곱의 합)

$
\frac{\partial E}{\partial u_ {ji}} = \frac{\partial E}{\partial z_ j} \frac{\partial z_ j}{\partial u_ {ji}} \\\ 
\frac{\partial E}{\partial z_ j} = \sum \limits_ {k=1}^{m} \frac{\partial E}{\partial o_ k}\frac{\partial o_ k}{\partial z_ j}  \\\ 
\sum \limits_ {k=1}^{m} (o_ k - t_ k) f'(osum_ k) v_ {kj} \\\ 
\frac{\partial z_ j}{\partial u_ {ji}} = \frac{\partial}{\partial u_ {ji}} zsum_ j = \sum \limits_ {i=1}^{d} u_ {ji} x_ i + u_ {j0} = x_ i * f'(zsum_ j) \\\ 
\therefore \frac{\partial E}{\partial v_ {kj}} = \sum \limits_ {i=1}^{d} (o_ k - t_ k) * v_ {kj} * f'(osum_ k) * x_ i * f'(zsum_ j)
$


# 분류 문제

## 종류

## 출력값 표현

부륙수만큼 자리수가있고, 해당하는 자리의 값이 1이면 원핫인코딩, 이게 좀더 자주쓰인다

# 오차 함수



---
layout: post
title: "YOLO, Object Detection Model" 
description: "YOLO, You Only Look Once"
categories: [DeepLeaning]
tags: [DeepLeaning, YOLO, Object Detection]
use_math: true
redirect_from:
  - /2022/02/04
---

* Kramdown table of contents
{:toc .toc} 

- [논문 리뷰](https://bkshin.tistory.com/entry/%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0-YOLOYou-Only-Look-Once)
- [How To Train](https://towardsdatascience.com/how-to-train-a-custom-object-detection-model-with-yolo-v5-917e9ce13208)
- [논문 리뷰 영상 1](https://www.youtube.com/watch?v=lxyCUfn_p4Q)
- [논문 리뷰 영상 2](https://www.youtube.com/watch?v=ccnL_ODHfys)

# 타 객체 검출기

## CNN

> CNN의 학습 대상은 필터

![image](https://user-images.githubusercontent.com/32366711/152748166-53809f3e-6a81-4c14-b60a-3b19cd047239.png)

~~~ python
model = Sequential()

# 특징 추출
model.add(Conv2D(12, kernel_size=(5, 5), activation='relu', input_shape=(120, 60, 1)))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(16, kernel_size=(5, 5), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(20, kernel_size=(4, 4), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

# 추출된 특징을 바탕으로 
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(4, activation='softmax'))
~~~

## DPM, Deformable parts models

> 이미지 전체를 슬라이딩 윈도(sliding window[^sl]) 방식으로 객체를 검출하는 모델

### 작동 방식

1. sliding window
2. block wise operation
3. shift or hot block wise orientation histogram
4. classification

각 영역을 생성한 후, 영역별로 feature 수집 및 분류 작업을 수행

각각의 특징들을 모두 추출(template filter)해내어 합산하여 특정 객체라고 판별하는 방식

ex. 만일 어떤 영역내에 사람, 얼굴, 몸, 손, 다리 등등의 필터를 씌운 후 높은 값을 가지고 있다면 이는 사람객체라고 판단할 수 있음

ex. 사람전체에ㄱ 대한 객체도 있지만, 이것만 쓰면 마네킹 등과 사람을 구별하기 힘들기에 각 특징에 대한 필터도 씌워서 합계를 냄


[^sl]: bounding box(window)를 일정 거리마다 그리는 방식

## R-CNN

`Regions with Convolutional Neuron Networks features`

> 각 객체에 대한 bounding box를 생성한 후, 각 박스가 어떤 객체인지 분류기를 적용한 모델

### 작동 방식

1. Extract Region proposals (Selective Search)
2. compute CNN features
3. Classify regions
  3.1 SVM
  3.2 Bounding Box Regression

[^SS]: 1. bounding box를 랜덤하게 작게 많이 생성한다. <br/> 2. 계층적 그룹핑 알고리즘을 사용해 조금씩 Merge한다. <br/> 3. 이를 바탕으로 ROI라는 영역을 제안하는 Region Proposal 형식으로 진행된다


# YOLO

> 객체 검출(Object Detection) 방식중 하나          
> 사람과 같이 사진을 한번만 보고 각 객체를 인식하는 것이 특징

기존의 객체 검출 모델들은, 분류기를 재정의하여 검출기로 사용하고 있음

## Unified Detection

> 전체 이미지를 그리드로 나눈 후, 어떤 객체의 중심이 특정 그리드 셀에 위치 한다면, 그 셀은 해당 객체를 검출해 내야 한다.

각 그리드 셀은, 셀에 존재하는 bouding box와 그 box에 대한 confidence score을 예측한다

condifence score이란, bouding box가 객체를 포함한다고 하는 것이 얼마나 믿음직하고, 정확한 것인지를 의미한다


@
\text{confidence score} = Pr(Object) * IOU_{pred}^{truth}
@[^IOU]

만일 그리드 셀에 아무 객체가 없다면, $Pr(Object)$는 0이 되며, 따라서 confidence score도 0이 된되며,
객체가 확실히 있다고 예측했을 때, 즉 $Pr(Object)$는 1이 되는 것이 갖아 이상적이다.

[^IOU]: Intersectioon Over Union. 객체의 실제 bounding box와 예측 bounding box의 합집합 면적 대비 교집합 면적 비율. 값이 작을수록 다른 객체, 값이 클수록 같은 객체


각각의 bounding box는 5개의 예측치, x, y, w, h ,condifence로 구성되어 있다.

- (x, y) : bounding box 중심의 그리드 셀 내 상대 위치 (0~1)
- (w, h) : 이미지 전체 너비, 높이 대비 bounding box의 너비. 높이 (0~1)
- confidence : confidence score

이때 각각의 그리드 셀은 conditional class probabilities(C)[^ccp]를 예측한다

이 값은 그리드 셀에 몇개의 bounding box가 있는지는 상관없이, 이 셀이 어떤 객체, class인지 확률 값만을 구한다.

@
C(\text{conditional class probabilities}) = Pr(Class_i | Object)
@

[^ccp]: 그리드 셀 안에 객체가 있다는 조건 하에, 그 객체가 어떤 객체인지에 대한 조건부 확률

@
\begin{align\*}
& \text{class specific confidence score} \\\ 
&= Pr(Class_i | Object) * Pr(Object) *  IOU_{pred}^{truth} \\\ 
&= Pr(Class_i) * IOU_{pred}^{truth}
\end{align\*}
@

이 점수는 bounding box에 특정 클래스 객체가 나타날 확률(bounding box가 맞을 확롤)과 예측된 bounding box가 그 클래스에 얼마나 잘 들어맞는지(class가 맞을 확률)를 나타낸다


### Network Design

> YOLO는 하나의 CNN구조이며,       
> 24개의 convolutional layer와 2개의 fully connected layer로 구성되어 있다

convolutional layer은 이미지로부터 특징을 추출하고, fully connected layer은 클래스 확률과 bounding box의 좌표를 예측한다


![image](https://user-images.githubusercontent.com/32366711/152728714-9103956d-6c98-4b0b-b86d-acac08fed20e.png)[^model]

<img width="1541" alt="image" src="https://user-images.githubusercontent.com/32366711/152730200-99f91f0f-b5f2-40bf-b60e-70473a5e0368.png">


최종적으로 7 * 7 * 30의 결과가 생기는데,

7 * 7 은 전체 이미지를 7칸으로 나눈 것이며, 30개의 deep 중

첫 10칸은 해당 셀을 중심으로 하는 bounding box 2개의 대한 설명이며, 이후 20칸은 해당 셀의 클래스에 대한 확률이다

즉 한 셀당, 박스가 2개씩 추천되며, 각 셀당 20개의 클래스에 대한 확률이 계산된다

[^model]: YOLO 연구진은 파스칼 VOC라는 이미지 인식 국제대회 데이터 셋을 이용해 실험하였으며, 7 * 7 그리드, Bounding box 2개를 설정했다(하이퍼 파라미터). 또한 VOC에는 20개의 라벨링 데이터가 존재했기에 최종적으로 7 * 7 * (5 * 2 + 20)이라는 예측 결과를 출력했다

이렇게 생긴 결과에서 셀당 Box가 2개씩, 총 98개의 Box가 생기는데, 이 박스가 특정 클래스일 확률을 계산할 수 있다(class specific confidence score).

이 상태를 그냥 출력하면 다음과 같이 98개의 모든 박스에서 확률이 가장 높은 객체로 출력이 된다

<img width="460" alt="image" src="https://user-images.githubusercontent.com/32366711/152731079-dcb60668-9911-479d-89de-66fe98963d81.png">

따라서, 각 class specific confidence score에서 임계값을 두어, 해당 값 이하일 경우 절대 아닐거라고 판별해 0으로 바꿔준다.

이 과정을 거치면, 불필요한 박스들은 생성되지 않으며, 객체가 겹쳐져있는 경우는 출력될 수 있다(0.4 0.5 등등의 애매한 값. 우리가 찾는건 0.95 등 높은 확률)

<img width="724" alt="image" src="https://user-images.githubusercontent.com/32366711/152731315-492478cf-ef9d-4eca-9969-e43c0d6e80ad.png">

이렇게 생성된 박스들 중에서 NMS[^NMS] 알고리즘을 사용하여 하나의 Box만 남겨줄 수 있다.

이때 경계 박스들이 겹쳐있지 않을 때에는(IoU값이 낮을 때), 서로 다른 오브젝트 경계 박스일 것이라두고 남겨두게 된다

[^NMS]: Non-maximal suppression 비-최대값 억제. object detector가 예측한 bounding box 중에서 정확한 bounding box를 선택하도록 하는 기법

#### NMS, Non-maximal suppression 

<img width="1221" alt="image" src="https://user-images.githubusercontent.com/32366711/152739057-27128b14-c663-47e1-b78e-45514fb2f406.png">

1. 하나의 클래스에 대한 bounding boxes 목록에서 가장 높은 점수를 갖고 있는 bounding box를 선택하고 목록에서 제거합니다. 그리고 final box에 추가합니다.
2. 선택된 bounding box를 bounding boxes 목록에 있는 모든 bounding box와 IoU를 계산하여 비교합니다. IoU[^IOU]가 threshold(YOLO에선 0.5로 정함)보다 높으면 bounding boxes 목록에서 제거합니다.
3. bounding boxes 목록에 남아있는 bounding box에서 가장 높은 점수를 갖고 있는 것을 선택하고 목록에서 제거합니다. 그리고 final box에 추가합니다.
4. 다시 선택된 bounding box를 목록에 있는 box들과 IoU를 비교합니다. threshold보다 높으면 목록에서 제거합니다.
5. bounding boxes에 아무것도 남아 있지 않을 때 까지 반복합니다.
6. 각각의 클래스에 대해 위 과정을 반복합니다. 

최종적으로 남은 값들은 서로다른 객체라고 판별하게 된다

### Train

마지막 계층은 선형 활성화 함수를 사용했고, (1차원 4096 -> 3차원 7 * 7 * 30)

이외의 모든 계층에는 Leaky ReLU[^leaky_ReLU]를 적용했다

@
\phi (x) =
\begin{cases}
x, & \text{ if } x > 0 \\\ 
0,1x & \text{ otherwise } 
\end{cases}
@

[^leaky_ReLU]: 활성화 함수. 0이상은 x, 0이만은 0.1x로 0이하의 값도 값을 살려서 사용. 기존의 ReLU는 0이하는 0

loss function은 SSE(Sum-Squared Error)를 기반으로 하였으며, 따라서 SSE를 최적화 해야한다.

기존의 SSE는 모든 가중치를 동일하게 두지만, YOLO는 Bounding Box의 위치와, class인 확률 두개를 계산해야 하기에, 이 두개를 동일한 가중치로 두어선 문제가 생길 수 있다.

또한 대부분의 셀에는 객체가 없다(배경). 따라서 SSE는 셀의 confidence score이 0이 되도록 학습하게 될 것이다.

이를 개선하기 위해 bounding box의 loss 가중치를 증가시키며(클래스를 특정 짓는것 보다, Box의 위치를 잘 잡는 것이 더 중요하다 판단), 객체가 존재하지 않는 bounding box 즉 confidence score이 0인 대상은 가중치는 감소시켰다

따라서 두가지의 가중치, $\lambda_ coord = 5$와 $\lambda_ noobj = 0.5$를 사용하였다

마지막으로, w,h 가 큰 Bounding Box와 작은 Box 모두 동일한 가중치를 사용하게 되는데,

작은 Box가 큰 Box보다 중심부 위치 변화에 더 민감하게 된다. 작은 Box는 조금만 움직여도 객체를 벗어날 수 있다.

이를 개선하기 위해 너비와 높이에는 squared root를 취하여 크기에 따라 증가율을 감소시켰다


- $\mathbb{1}_ {ij}^{obj}$ : 셀 i의 j번째 bouinding box predictor가 사용되는가
- $\mathbb{1}_ {i}^{obj}$ : 셀 i에 객체가 존재하는지 여부, 존재하면 1, 없으면 0
- $\lambda_ coord$ : 위치에 대한 가중치 (5)
- $\lambda_ noobj$ : 객체가 없는 박스에 대한 가중치. (0.5)

@
\begin{align}
 & \lambda_{coord} \sum\limits_ {i=0}^{S^2}\sum\limits_ {j=0}^{B} \mathbb{1}_ {ij}^{obj} \[ (x_ i - \hat{x}_ i)^2 + (y_ i - \hat{y}_ i)^2 \] \\\ 
 &+ \lambda_{coord} \sum\limits_ {i=0}^{S^2}\sum\limits_ {j=0}^{B} \mathbb{1}_ {ij}^{obj} \[ (\sqrt{w_ i} - \sqrt{\hat{w}_ i} )^2 + (\sqrt{h_ i} - \sqrt{\hat{h}_ i})^2 \] \\\ 
 &+ \sum\limits_ {i=0}^{S^2}\sum\limits_ {j=0}^{B} \mathbb{1}_ {ij}^{obj} (C_ i - \hat{C}_ i)^2 \\\ 
 &+ \lambda_{noobj} \sum\limits_ {i=0}^{S^2}\sum\limits_ {j=0}^{B} \mathbb{1}_ {ij}^{noobj} (C_ i - \hat{C}_ i)^2 \\\ 
 &+ \sum\limits_ {i=0}^{S^2} \mathbb{1}_ {i}^{obj} \sum_ {c \in \text{classes} } (p_ i (c) - \hat{p}_ i (c))^2
\end{align}
@

- 1) 객체가 존재하는 셀 i의 x,y의 loss
- 2) 객체가 존재하는 셀 i의 w,h의 loss
- 3) 객체가 존재하는 셀 i의 cindifence score의 loss
- 4) 객체가 존재하지 않는 셀 i의 condifence score의 loss [^4]
- 5) 객체가 존재하는 셀 i에 conditional class probability (객체가 나타날 확률)의 loss

[^4]: 원래는 3번과 4번을 합쳐서 $\sum\limits_ {i=0}^{S^2}\sum\limits_ {j=0}^{B} (C_ i - \hat{C}_ i)^2$ 라고 쓸 수도 있지만, 객체가 존재하는 값과 객체가 없는 값에 가중치를 따로 분리해서 계산해주기로 했기 때문에 두개로 나누었다

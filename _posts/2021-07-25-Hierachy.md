---
layout: post
title: "기계학습, Hierachy Clustering"
description: "Hierachy Clustering, 계층적 군집 분석"
categories: [MachineLearning]
tags: [Machine Learning, Unsupervised Learning, Hierachy, Clustering]
use_math: true
redirect_from:
  - /2021/07/25/
---

* Kramdown table of contents
{:toc .toc}      

[1](https://ratsgo.github.io/machine%20learning/2017/04/18/HC/){:target="_ blank"}          
[2](https://towardsdatascience.com/hierarchical-clustering-agglomerative-and-divisive-explained-342e6b20d710){:target="_ blank"}        
[3](https://stackabuse.com/hierarchical-clustering-with-python-and-scikit-learn){:target="_ blank"}        
[4](https://kr.mathworks.com/help/stats/dendrogram.html)
[5](https://scikit-learn.org/stable/auto_examples/cluster/plot_agglomerative_dendrogram.html#sphx-glr-auto-examples-cluster-plot-agglomerative-dendrogram-py)
[6](https://medium.com/swlh/hierarchical-clustering-in-python-9646cfddee35)

# Hierachy Clustering 
   
> 군집간의 거리(유사도)를 기반으로 계층을 나누어 클러스터링을 하는 알고리즘이며, K Means와는 다르게 군집의 수를 미리 정해주지 않아도 됨            
> 클러스터링 결과 는 일반적으로 덴드로그램 으로 표시한다
ex ) 종 -> 속 -> 강 -> 목 -> 과 -> 문 -> 계 순으로 묶어가며 하나의 그룹으로 만들어가는 과정

## Agglomerative, 병합

> Bottom-Up 방식      
> 비슷한 군집끼리 묶어 가면서 최종 적으로는 하나의 케이스가 될때까지 군집을 묶는 클러스터링 알고리즘           

![image](https://user-images.githubusercontent.com/32366711/126897534-0e5a7f15-cbf2-453d-9ed3-97e227bc903d.png)

![image](https://user-images.githubusercontent.com/32366711/126901230-ccf0c013-de20-4e42-a026-02d425e18ac5.png){: width="350"}{: .aligncenter}


## Divisive, 분할

> Top-Down 방식      
> 일단 하나의 군집으로 묶은 후, 유사하지 않은 군집을 분할해가는 클러스터링 알고리즘


## 거리의 기준

군집 - 군집 간에 거리는?

1. 요소간 거리중 최소거리를 기준으로 ( Single Linkage )         
2. 요소간 거리중 최대거리를 기준으로 ( Complete Linkage )          
3. 요소간 거리의 평균 거리를 기준으로 ( Average Linkage )               
4. 군집의 중심간 거리를 기준으로 ( Centroid )             

## Dendrogram

> 계층으로 나눈 라벨들을 각각의 거리로 어떻게 나누어졌는지 보기 편하게 그린 플롯


# Practice


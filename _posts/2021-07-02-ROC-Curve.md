---
layout: post
title: "기계학습, ROC Curve"
description: "ROC Curve"
categories: [MachineLearning]
tags: [Machine Learning, Supervised Learning, Logistic Regression, Regression, ROC Curve]
use_math: true
redirect_from:
  - /2021/07/03/
---

* Kramdown table of contents
{:toc .toc}

# Logistic Regression
 

# 민감도, 특이도    

|실제\\추측 | False | True |
|:---:|:---:|:---:|
|Positive|<span style="color:red">False Positive</span><br /><span style="color:blue">Type I Error</span>|True Positive|    
|Negative|True Negative|<span style="color:red"> False Negative</span><br /><span style="color:blue"> Type II Error </span>|    

- 민감도 Sensitivity     
Recall, TPR, True Positive Rate = $\;\; \frac{TP}{TP + FN} $    
실제 병에 걸린 사람이 양성(Positive) 판정을 받는 비율 (피관찰자 기준)    
    
<br />    
        
- 특이도 Specificity    
TNR, True Negative Rate = $\;\; \frac{TN}{FP + TN} $    
정상인이 음성(Negative) 판정을 받는 비율    
    
<br />    
        
- FPR, False Positive Rate, Type I Error Rate    
1 - Specifity = $\;\; \frac{FP}{FP + TN} $    
<br />    
     
- 정확도 Accuracy = $\;\; \frac{TP + TN}{TP + FP + FN + TN} $    
전체 데이터중 제대로 분류된 데이터 비율    
<br />    
    
- 에러율 Error Rate = $\;\; \frac{FP + FN}{TP + FP + FN + TN} $    
전체 데이터중 제대로 분류되지 않은 데이터 비율  
<br />    

- 정밀도 Precision = $\;\; \frac{TP}{TP + FP} $    
Positive로 예측했을 때 실제로 Positive인 비율 (관찰자 기준)     
<br />    


# ROC Curve    
> 수신자 조작 특성 (Receiver Operating Characteristic)      
> 다양한 threshold(임계값)에 대한 이진분류기의 성능을 한번에 표시한 것
> 좌상단에 붙어있을 수록(곡선 아래 면적이 넓을 수록) 좋음    
> = 면적이 1에 가까울 수록 좋은 분류기    
![image](https://user-images.githubusercontent.com/32366711/124346110-01a74f80-dc18-11eb-9546-5ede0492c1a3.png)[^공돌이의 수학정리 노트]

## TPR, FPR이란    
TPR : 있을 때 있다고 한것. 병이 있는데, 병이 있다고 하는 것
FPR : 없을 때 있다고 한 것. 병이 없는데, 있다고 하는 것

![image](https://user-images.githubusercontent.com/32366711/124346455-daea1880-dc19-11eb-8b4a-a8ffd299cf87.png)[^공돌이의 수학정리 노트]

## 점의 위치의 의미    
> 곡선위의 점은 임계값의 위치에따른 TPR, FPR을 의미함    
![image](https://user-images.githubusercontent.com/32366711/124346465-e9383480-dc19-11eb-84db-fbbd6aba44ab.png)[^공돌이의 수학정리 노트]

## 곡선의 휨 정도의 의미    
> 곡선이 위에 붙을 수록, TPR, FPR을 더 잘 구분할 수 있다는 의미    
![image](https://user-images.githubusercontent.com/32366711/124346501-27cdef00-dc1a-11eb-9b7d-ba31c422c55b.png)[^공돌이의 수학정리 노트]


logistic regression output is probabilities         
If probability is higher than 0.5 data is labeled 1(abnormal) else 0(normal)         
By default logistic regression threshold is 0.5           
ROC is receiver operationg characteristic. In this curve x axis is false positive rate and y axis is true positive rate            
If the curve in plot is closer to left-top corner, test is more accurate.        
Roc curve score is auc that is computation area under the curve from prediction scores          
We want auc to closer 1            
fpr = False Positive Rate           
tpr = True Positive Rate            
If you want, I made ROC, Random forest and K fold CV in this tutorial. 
[roc-curve-with-k-fold-c](https://www.kaggle.com/kanncaa1/roc-curve-with-k-fold-cv/){: target = "_ blank"}           


# 참고 사이트
- [로스카츠의 AI 머신러닝](https://losskatsu.github.io/machine-learning/stat-roc-curve/#2-%EB%AF%BC%EA%B0%90%EB%8F%84%EC%99%80-%ED%8A%B9%EC%9D%B4%EB%8F%84){: target="_ blank"}    
- [공돌이의 수학정리 노트](https://angeloyeo.github.io/2020/08/05/ROC.html){: target="_ blank"}

[^공돌이의 수학정리 노트] : https://angeloyeo.github.io/2020/08/05/ROC.html

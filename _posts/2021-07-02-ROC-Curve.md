---
layout: post
title: "기계학습, ROC Curve"
description: "ROC Curve"
categories: [MachineLearning]
tags: [Machine Learning, Supervised Learning, ROC Curve]
use_math: true
redirect_from:
  - /2021/07/02/
---

* Kramdown table of contents
{:toc .toc}


# 민감도, 특이도    

|실제\\추측 | False | True |
|:---:|:---:|:---:|
|Positive|<span style="color:red">False Positive</span><br /><span style="color:blue">Type I Error</span>|True Positive|    
|Negative|True Negative|<span style="color:red"> False Negative</span><br /><span style="color:blue"> Type II Error </span>|    


<br />

- 민감도 Sensitivity     
Recall, TPR, True Positive Rate = $\;\; \frac{TP}{TP + FN} $    
실제 병에 걸린 사람이 양성(Positive) 판정을 받는 비율 (피관찰자 기준)    
<br />    
        
- 특이도 Specificity    
TNR, True Negative Rate = $\;\; \frac{TN}{FP + TN} $    
정상인이 음성(Negative) 판정을 받는 비율    
<br />    
        
- FPR, False Positive Rate, Type I Error Rate    
1 - Specifity = $\;\; \frac{FP}{FP + TN} $    
<br />    
     
- 정확도 Accuracy = $\;\; \frac{TP + TN}{TP + FP + FN + TN} $    
전체 데이터중 제대로 분류된 데이터 비율    
<br />    
    
- 에러율 Error Rate = $\;\; \frac{FP + FN}{TP + FP + FN + TN} $    
전체 데이터중 제대로 분류되지 않은 데이터 비율  
<br />    

- 정밀도 Precision = $\;\; \frac{TP}{TP + FP} $    
Positive로 예측했을 때 실제로 Positive인 비율 (관찰자 기준)     
<br />    


# ROC Curve    
> 수신자 조작 특성 (Receiver Operating Characteristic)[^1]      
> 다양한 threshold(임계값)에 대한 이진분류기의 성능을 한번에 표시한 것    
> 좌상단에 붙어있을 수록(곡선 아래 면적이 넓을 수록) 좋은 분류기    

![image](https://user-images.githubusercontent.com/32366711/124377376-9d9f8c80-dce6-11eb-98ef-57e6af7a0ae4.png)    


## 1. TPR, FPR이란    
> TPR : 있을 때 있다고 한것. 병이 있는데, 병이 있다고 하는 것    
> FPR : 없을 때 있다고 한 것. 병이 없는데, 있다고 하는 것[^1]    

![image](https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2020-08-05-ROC/pic3.png)

## 2. 점의 위치의 의미    
> 곡선위의 점은 임계값의 위치에따른 TPR, FPR을 의미함[^1]    

![image](https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2020-08-05-ROC/pic6.gif) 

## 3. 곡선의 휨 정도의 의미    
> 곡선이 위에 붙을 수록, TPR, FPR을 더 잘 구분할 수 있다는 의미[^1]     
   
![image](https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2020-08-05-ROC/pic7.gif)    

## 4. 면적에 대한 의미    
> 면적은 분류기의 성능    

|  AUC <br/>(Area Under Curve) | Evaluation |
|:--------------------:|:----------:|
|       0.9 ~          |  Excellent |
|     0.8 ~ 0.9     |    Good    |
|     0.7 ~ 0.8     |    Fair    |
|     0.6 ~ 0.7     |    Poor    |
|        ~ 0.6         |    Fail    |


## practice    
[roc-curve-with-k-fold-c](https://www.kaggle.com/kanncaa1/roc-curve-with-k-fold-cv/){: target = "_ blank"}           
[코드](https://www.kaggle.com/s1hyeon/roc-curve-with-k-fold-cv/edit){: target="_ blank"}       

~~~ python   
# from numpy import interp
# from sklearn.ensemble import RandomForestClassifier
# from sklearn.metrics import roc_curve,auc

# Convert string label to float : male = 1, female = 0
dict = {'label':{'male':1,'female':0}}      # label = column name
data.replace(dict,inplace = True)           # replace = str to numerical
x = data.loc[:, data.columns != 'label']
y = data.loc[:,'label']

random_state = np.random.RandomState(0)
clf = RandomForestClassifier(random_state=random_state)
cv = StratifiedKFold(n_splits=5,shuffle=False)

# plot arrows
fig1 = plt.figure(figsize=[12,12])
ax1 = fig1.add_subplot(111,aspect = 'equal')
ax1.add_patch(
    patches.Arrow(0.45,0.5,-0.25,0.25,width=0.3,color='green',alpha = 0.5)
    )
ax1.add_patch(
    patches.Arrow(0.5,0.45,0.25,-0.25,width=0.3,color='red',alpha = 0.5)
    )
tprs = []
aucs = []
mean_fpr = np.linspace(0,1,100)
i = 1
for train,test in cv.split(x,y):
    prediction = clf.fit(x.iloc[train],y.iloc[train]).predict_proba(x.iloc[test])
    fpr, tpr, t = roc_curve(y[test], prediction[:, 1])
    tprs.append(interp(mean_fpr, fpr, tpr))
    roc_auc = auc(fpr, tpr)
    aucs.append(roc_auc)
    plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))
    i= i+1

plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')
mean_tpr = np.mean(tprs, axis=0)
mean_auc = auc(mean_fpr, mean_tpr)
plt.plot(mean_fpr, mean_tpr, color='blue',
         label=r'Mean ROC (AUC = %0.2f )' % (mean_auc),lw=2, alpha=1)

plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC')
plt.legend(loc="lower right")
plt.text(0.32,0.7,'More accurate area',fontsize = 12)
plt.text(0.63,0.4,'Less accurate area',fontsize = 12)
plt.show()
~~~    

![image](https://user-images.githubusercontent.com/32366711/124379056-bb252400-dcef-11eb-89a6-5b41e647c5ff.png)    


# 참고 사이트
- [로스카츠의 AI 머신러닝](https://losskatsu.github.io/machine-learning/stat-roc-curve/#2-%EB%AF%BC%EA%B0%90%EB%8F%84%EC%99%80-%ED%8A%B9%EC%9D%B4%EB%8F%84){: target="_ blank"}    
- [공돌이의 수학정리 노트](https://angeloyeo.github.io/2020/08/05/ROC.html){: target="_ blank"}




[^1]: 공돌이의 수학정리 노트, https://angeloyeo.github.io/2020/08/05/ROC.html
